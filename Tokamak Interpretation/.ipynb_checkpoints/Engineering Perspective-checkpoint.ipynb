{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b678ed4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d243ad3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import tokamakTK\n",
    "from tokamakTK import get_ECT_regression, HUEOrder, get_pi_matrix, clean_numerical_data, MyCounter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from PIL import Image\n",
    "#import imageio\n",
    "import imageio.v2 as imageio\n",
    "from matplotlib.lines import Line2D\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.colors as mcolors\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.subplots as plsp\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.rc('font',family = 'serif')\n",
    "plt.rcParams[\"mathtext.fontset\"] = \"cm\"\n",
    "\n",
    "path = \"../data/\"\n",
    "fig_path = \"../../../LATEX/Latex Images/\"\n",
    "\n",
    "coeffs = ['IP', 'BT', 'NEL', 'PLTH', 'RGEO', 'KAREA', 'EPS', 'MEFF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22f6b747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Subset that decrease alpha-R to 0.6357\n",
      "--------\n",
      "23.45% affected alpha_R\n",
      "76.55% did not affect alpha_R\n",
      "\n",
      "\n",
      "  Subset that decrease alpha-R to 0.9998\n",
      "--------\n",
      "9.88% affected alpha_R\n",
      "90.12% did not affect alpha_R\n",
      "\n",
      "\n",
      "  Subset given by Joseph Hall           \n",
      "--------\n",
      "18.46% affected alpha_R\n",
      "81.54% did not affect alpha_R\n"
     ]
    }
   ],
   "source": [
    "# Obtained from Optimization\n",
    "\n",
    "min_subset_ids_6357 = pd.read_csv(path+\"R_ids_alpha_0.6357.csv\")\n",
    "min_subset_ids_9998 = pd.read_csv(path+\"R_ids_alpha_0.9998.csv\")\n",
    "min_subset_ids_joe  = pd.read_csv(path+\"deviation_id.csv\")\n",
    "\n",
    "DB2 = pd.read_csv(path+\"DB2P8.csv\")\n",
    "DB5 = pd.read_csv(path+\"SELDB5_SVD.csv\", low_memory=False) \n",
    "\n",
    "# Setting ELMy Dataset\n",
    "DB5 = DB5[DB5[\"PHASE\"].isin(['HGELM', 'HSELM', 'HGELMH', 'HSELMH'])]\n",
    "\n",
    "# Removing Spherical TOKAMAKS\n",
    "#DB5 = DB5[~DB5[\"TOK\"].isin(['START','MAST','NSTX'])]\n",
    "\n",
    "# There is two shots from DB2P8 missing in DB5\n",
    "missing_shots = DB2[~DB2.id.isin( DB5.id.values )].reset_index(drop=True)\n",
    "DB5 = pd.concat([DB5, missing_shots], axis=0, ignore_index=True)\n",
    "\n",
    "# Labeling shots that had great impact in decreasing alpha_R\n",
    "DB5.insert(loc=2,column=\"label_6357\",value=[\"Unaffected\"]*len(DB5))\n",
    "DB5.loc[(DB5[DB5.id.isin(min_subset_ids_6357.id)].index), \"label_6357\"] = \"Decreasing\"\n",
    "\n",
    "DB5.insert(loc=2,column=\"label_9998\",value=[\"Unaffected\"]*len(DB5))\n",
    "DB5.loc[(DB5[DB5.id.isin(min_subset_ids_9998.id)].index), \"label_9998\"] = \"Decreasing\"\n",
    "\n",
    "DB5.insert(loc=2,column=\"label_joe\",value=[\"Unaffected\"]*len(DB5))\n",
    "DB5.loc[(DB5[DB5.id.isin(min_subset_ids_joe.id)].index), \"label_joe\"] = \"Decreasing\"\n",
    "\n",
    "DB5.insert(loc=2,column=\"Spherical\",value=[\"No Spherical\"]*len(DB5))\n",
    "DB5.loc[(DB5[DB5.TOK.isin(['START','MAST','NSTX'])].index), \"Spherical\"] = \"Spherical\"\n",
    "\n",
    "DB5.insert(0, 'intercept', np.ones(len(DB5)))\n",
    "\n",
    "\n",
    "print(\n",
    "    \"  Subset that decrease alpha-R to 0.6357\\n--------\\n\" +\n",
    "    f\"{ round( (len(min_subset_ids_6357)/len(DB5))*100     ,2)  }% affected alpha_R\\n\" + \n",
    "    f\"{ round( (1 - len(min_subset_ids_6357)/len(DB5))*100 ,2)  }% did not affect alpha_R\" +\n",
    "    \"\\n\\n\\n  Subset that decrease alpha-R to 0.9998\\n--------\\n\" +\n",
    "    f\"{ round( (len(min_subset_ids_9998)/len(DB5))*100     ,2)  }% affected alpha_R\\n\" + \n",
    "    f\"{ round( (1 - len(min_subset_ids_9998)/len(DB5))*100 ,2)  }% did not affect alpha_R\"\n",
    "    \"\\n\\n\\n  Subset given by Joseph Hall           \\n--------\\n\" +\n",
    "    f\"{ round( (len(min_subset_ids_joe)/len(DB5))*100     ,2)  }% affected alpha_R\\n\" + \n",
    "    f\"{ round( (1 - len(min_subset_ids_joe)/len(DB5))*100 ,2)  }% did not affect alpha_R\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "16d0764a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB5 = tokamakTK.clean_categorical_data(DB5)\n",
    "\n",
    "\n",
    "def get_HUEORDER(DB5,c=\"tab20\"):\n",
    "    # Needed for Improved Visualization: 2D and 3D Plots\n",
    "    HUE_ORDER, PX_ORDER = tokamakTK.get_colors_per_category(DB5,c)\n",
    "    hue_order = HUEOrder(HUE_ORDER)\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "\n",
    "    # SPECIAL PARAMETERS\n",
    "    colors_ = sns.color_palette(c, 20)\n",
    "    HUE_ORDER[\"Spherical\"] = dict(zip(sorted(DB5[\"Spherical\"].unique()), colors_[:len(DB5[\"Spherical\"].unique())]))\n",
    "    HUE_ORDER[\"label_joe\"] = dict(zip(sorted(DB5[\"label_joe\"].unique()), colors_[:len(DB5[\"label_joe\"].unique())]))\n",
    "    HUE_ORDER[\"TOK\"][\"START\"] = (0.8235, 0.5055, 0.4412)\n",
    "    \n",
    "    return HUE_ORDER, PX_ORDER\n",
    "\n",
    "HUE_ORDER, PX_ORDER = get_HUEORDER(DB5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "55a3883b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = DB5[DB5.label_6357.isin([\"Decreasing\"])].reset_index(drop=True)\n",
    "data2 = DB5[DB5.label_6357.isin([\"Unaffected\"])].reset_index(drop=True)\n",
    "data2 = data2[~data2.id.isin(DB2.id.values)].reset_index(drop=True)\n",
    "\n",
    "data = [data1,data2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "0d4c56da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4942"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data1)+len(data2)#+len(DB2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b1f2c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_3D_plot_DB5(db5, indxs, parameter, saveFig=False, file_name=\"\", remSPH=False):\n",
    "    # Create a figure and a 3D axis\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    alpha = round(\n",
    "        get_ECT_regression(\n",
    "            DB5[DB5.id.isin(DB2.id.values) | DB5.id.isin(indxs.id.values)]\n",
    "        ).params[\"RGEO\"], 2\n",
    "    )\n",
    "    \n",
    "    data = db5.copy()\n",
    "    x, y, z = \"NUSTAR\", \"RHOSTAR\", \"Q95\"\n",
    "    \n",
    "    y_sp = (11, 20, 13)\n",
    "    if remSPH:\n",
    "        data = data[~data.TOK.isin(['START','MAST','NSTX'])]\n",
    "        y_sp = (11, 25, 11)\n",
    "        if parameter==\"TOK\":\n",
    "            HUE_ORDER[parameter].pop('START')\n",
    "            HUE_ORDER[parameter].pop('MAST')\n",
    "            HUE_ORDER[parameter].pop('NSTX')\n",
    "            print(\"Remember to re-run HUE_ORDER\")\n",
    "    \n",
    "    data[\"colors\"] = data[parameter].map(HUE_ORDER[parameter])\n",
    "    \n",
    "    \n",
    "    \n",
    "    scatter = ax.scatter(data[x], data[y], data[z], c=data[\"colors\"].values)\n",
    "    ax.set_xlabel(x, fontsize=11, labelpad=7)\n",
    "    ax.set_ylabel(y, fontsize=y_sp[0], labelpad=y_sp[1])\n",
    "    ax.set_zlabel(z, fontsize=11, rotation=90)  \n",
    "    ax.tick_params(axis='x', labelsize=13)\n",
    "    ax.tick_params(axis='y', labelsize=y_sp[2])\n",
    "    ax.tick_params(axis='z', labelsize=13)\n",
    "    \n",
    "    #ax.set_title(\"STDB5 without Spherical Tokamaks\")\n",
    "    \n",
    "    ax.set_yticks(ax.get_yticks())\n",
    "    ax.set_yticklabels(ax.get_yticks(), rotation=45)\n",
    "    \n",
    "    # Add a legend\n",
    "    legend_elements = []\n",
    "    for category, color in HUE_ORDER[parameter].items():\n",
    "        legend_elements.append(plt.Line2D([0], [0], marker='o', \n",
    "                                          color='w', label=category, markerfacecolor=color, markersize=7))\n",
    "    legend = ax.legend(handles=legend_elements, frameon=False,\n",
    "                       loc='upper right', bbox_to_anchor=(1.3, 0.9), fontsize=8)\n",
    "\n",
    "    \n",
    "    ax.view_init(elev=15, azim=200)\n",
    "    \n",
    "    if saveFig:\n",
    "        #plt.savefig(path + file_name)\n",
    "        plt.savefig(path + file_name, format=\"pdf\", dpi=800)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "984f1c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_3D_plot_DB5(DB5, min_subset_ids_6357, \"WALMAT\", saveFig=False, file_name=\"\", remSPH=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38017127",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_3D_plot_DB5(DB5, min_subset_ids_6357, \"DIVMAT\", saveFig=False, file_name=\"\", remSPH=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b126b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_twoprms3D_plot_DB5(db5, indxs, rotation, parameters, saveFig=False, file_name=\"\", remSPH=False):\n",
    "    # Create a figure and a 3D axis\n",
    "    alpha = round(\n",
    "        get_ECT_regression(\n",
    "            DB5[DB5.id.isin(DB2.id.values) | DB5.id.isin(indxs.id.values)]\n",
    "        ).params[\"RGEO\"], 2\n",
    "    )\n",
    "    \n",
    "    HUE_ORDER_0 = get_HUEORDER(db5, parameter, c=\"tab10\").copy()\n",
    "    HUE_ORDER_1 = get_HUEORDER(db5, parameter, c=\"Set3\").copy()\n",
    "    \n",
    "    data = db5.copy()\n",
    "    data[parameters[0]] = data[parameters[0]].str.replace(\"UNKNOWN\",\"UNK.\", regex=False)\n",
    "    data[parameters[1]] = data[parameters[1]].str.replace(\"UNKNOWN\",\"UNK.\", regex=False)\n",
    "    \n",
    "    HUE_ORDER_0[parameters[0]][\"UNK.\"] = HUE_ORDER_0[parameters[0]][\"UNKNOWN\"]\n",
    "    HUE_ORDER_0[parameters[0]].pop(\"UNKNOWN\")\n",
    "    \n",
    "    HUE_ORDER_1[parameters[1]][\"UNK.\"] = HUE_ORDER_1[parameters[1]][\"UNKNOWN\"]\n",
    "    HUE_ORDER_1[parameters[1]].pop(\"UNKNOWN\")\n",
    "    \n",
    "    HUE_ORDER_0[parameters[0]][\"UNK.\"] = (0, 0, 0)\n",
    "    HUE_ORDER_1[parameters[1]][\"UNK.\"] = (0, 0, 0)\n",
    "    \n",
    "    x, y, z = \"NUSTAR\", \"RHOSTAR\", \"Q95\"\n",
    "    \n",
    "    y_sp = (11, 20, 13)\n",
    "    if remSPH:\n",
    "        data = data[~data.TOK.isin(['START','MAST','NSTX'])]\n",
    "        y_sp = (11, 25, 11)\n",
    "        if parameters[0]==\"TOK\":\n",
    "            HUE_ORDER_0[parameters[0]].pop('START')\n",
    "            HUE_ORDER_0[parameters[0]].pop('MAST')\n",
    "            HUE_ORDER_0[parameters[0]].pop('NSTX')\n",
    "            print(\"Remember to re-run HUE_ORDER\")\n",
    "        elif parameters[1]==\"TOK\":\n",
    "            HUE_ORDER_1[parameters[1]].pop('START')\n",
    "            HUE_ORDER_1[parameters[1]].pop('MAST')\n",
    "            HUE_ORDER_1[parameters[1]].pop('NSTX')\n",
    "            print(\"Remember to re-run HUE_ORDER\")\n",
    "    \n",
    "    data[\"colors1\"] = data[parameters[0]].map(HUE_ORDER_0[parameters[0]])\n",
    "    data[\"colors2\"] = data[parameters[1]].map(HUE_ORDER_1[parameters[1]])\n",
    "    \n",
    "\n",
    "    fig = plt.figure(figsize=(13, 4.5))\n",
    "    ax1 = fig.add_subplot(121, projection='3d')\n",
    "    ax2 = fig.add_subplot(122, projection='3d')\n",
    "    \n",
    "    # Adjust subplot positions\n",
    "    fig.subplots_adjust(wspace=0.05)\n",
    "    \n",
    "    \n",
    "    scatter = ax1.scatter(data[x], data[y], data[z], c=data[\"colors1\"].values)\n",
    "    ax1.set_xlabel(x, fontsize=11, labelpad=7)\n",
    "    ax1.set_ylabel(y, fontsize=y_sp[0], labelpad=y_sp[1])\n",
    "    ax1.set_zlabel(z, fontsize=11, rotation=90)  \n",
    "    ax1.tick_params(axis='x', labelsize=13)\n",
    "    ax1.tick_params(axis='y', labelsize=y_sp[2])\n",
    "    ax1.tick_params(axis='z', labelsize=13)\n",
    "    \n",
    "    ax1.set_yticks(ax1.get_yticks())\n",
    "    ax1.set_yticklabels(ax1.get_yticks(), rotation=45)\n",
    "\n",
    "\n",
    "    ax1.view_init(elev=15, azim=rotation)\n",
    "\n",
    "\n",
    "    # GETTING THE SECOND PLOT\n",
    "\n",
    "\n",
    "    scatter = ax2.scatter(data[x], data[y], data[z], c=data[\"colors2\"].values)\n",
    "    ax2.set_xlabel(x, fontsize=11, labelpad=7)\n",
    "    ax2.set_ylabel(y, fontsize=y_sp[0], labelpad=y_sp[1])\n",
    "    ax2.zaxis.set_label_text(z, fontsize=11, rotation=90)  \n",
    "    ax2.tick_params(axis='x', labelsize=13)\n",
    "    ax2.tick_params(axis='y', labelsize=y_sp[2])\n",
    "    ax2.tick_params(axis='z', labelsize=13)\n",
    "    \n",
    "    ax2.set_yticks(ax2.get_yticks())\n",
    "    ax2.set_yticklabels(ax2.get_yticks(), rotation=45)\n",
    "    \n",
    "    ax2.view_init(elev=15, azim=rotation)\n",
    "    \n",
    "    # Add a legend | COMMENT WHEN ROTATING\n",
    "    \n",
    "    legend_elements = []\n",
    "    for category, color in HUE_ORDER_0[parameters[0]].items():\n",
    "        legend_elements.append(plt.Line2D([0], [0], marker='o', \n",
    "                                          color='w', label=category, markerfacecolor=color, markersize=7))\n",
    "    legend = ax1.legend(handles=legend_elements, frameon=False,\n",
    "                       loc='upper right', bbox_to_anchor=(1.27, 0.9), fontsize=8)\n",
    "    \n",
    "    legend_elements = []\n",
    "    for category, color in HUE_ORDER_1[parameters[1]].items():\n",
    "        legend_elements.append(plt.Line2D([1], [1], marker='o', \n",
    "                                          color='w', label=category, markerfacecolor=color, markersize=7))\n",
    "    legend = ax2.legend(handles=legend_elements, frameon=False,\n",
    "                       loc='upper right', bbox_to_anchor=(1.27, 0.9), fontsize=8)\n",
    "    \n",
    "    ax1.annotate(parameters[0], xy=(1, 0.9), xycoords='axes fraction',\n",
    "                 fontsize=10, fontweight='bold')\n",
    "    ax2.annotate(parameters[1], xy=(1, 0.9), xycoords='axes fraction',\n",
    "                 fontsize=10, fontweight='bold')\n",
    "    \n",
    "    \n",
    "    if saveFig:\n",
    "        plt.savefig(path + file_name)\n",
    "        #plt.savefig(path + file_name, format=\"pdf\", dpi=800)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d3544c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_two3D_plot_DB5(DB5, min_subset_ids_6357, 200, [\"WALMAT\", \"DIVMAT\"], \n",
    "#                   saveFig=True, file_name=\"Material_Analysis.pdf\", remSPH=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d20fb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_two3D_plot_DB5(DB5, min_subset_ids_6357, 200, [\"WALMAT\", \"DIVMAT\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf05ac2",
   "metadata": {},
   "source": [
    "## Two Params\n",
    "\n",
    "```Python\n",
    "for r in np.linspace(0,360, 360//2):\n",
    "    file_name = f\"GIF_images/image_{int(r)}.png\"\n",
    "    get_two3D_plot_DB5(DB5, min_subset_ids_6357, int(r),\n",
    "                       [\"WALMAT\", \"DIVMAT\"], saveFig=True, file_name=file_name\n",
    "                      )\n",
    "\n",
    "x,y,z = \"NUSTAR\", \"RHOSTAR\", \"Q95\"\n",
    "\n",
    "image_folder = path+\"GIF_images/\"  # Path to the folder containing the images\n",
    "output_file = path+\"/GIFs/\"+f\"roMAT{x[0]}{y[0]}{z[0]}.gif\"  # Output file name\n",
    "\n",
    "# Get a list of PNG files in the folder\n",
    "image_files = [os.path.join(image_folder, file) for file in os.listdir(image_folder) if file.endswith('.png')]\n",
    "# Sort the image files by their numerical values in the filenames\n",
    "image_files.sort(key=lambda x: int(os.path.splitext(os.path.basename(x))[0].split('_')[-1]))\n",
    "\n",
    "# Save the images in the folder as an animated GIF\n",
    "imageio.mimsave(output_file, [imageio.imread(file) for file in image_files], fps=7)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "52a64d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb # For debugging || pdb.set_trace()\n",
    "\n",
    "def get_twods3D_plot_DB5(db5, data, rotation, parameter, stationary=True, saveFig=False, file_name=\"\", remSPH=False):\n",
    "    \n",
    "    \n",
    "    colors_dict = { # WALMAT\n",
    "        'NONE': '#FF0000',\n",
    "        'BE': '#0000FF',\n",
    "        'C': '#A84547',\n",
    "        #'C/SS': '#800080',\n",
    "        'C/W': '#CCCC00',\n",
    "        #'IN': '#0000FF',\n",
    "        #'IN/C': '#ADD8E6',\n",
    "        #'SS': '#FA8072',\n",
    "        'MO': '#ADD8E6',\n",
    "        'W': '#FF8C00',\n",
    "        'UNK.': '#000000',\n",
    "    }\n",
    "    \n",
    "    # ['NONE', 'C', 'C/W', 'W', 'MO', 'BE', 'UNKNOWN'] | LIMMAT\n",
    "    \n",
    "    \n",
    "    \"\"\"HUE_ORDER = get_HUEORDER(db5, c=\"tab10\")[0].copy()\n",
    "    colors_dict = HUE_ORDER[parameter]\n",
    "    HUE_ORDER[parameter][\"UNK.\"] = (0,0,0)\n",
    "    HUE_ORDER[parameter].pop(\"UNKNOWN\")\"\"\"\n",
    "    \n",
    "    \n",
    "    db5_  = db5.copy()\n",
    "    data1 = data[0].copy()\n",
    "    data2 = data[1].copy()\n",
    "        \n",
    "    data1[parameter] = data1[parameter].str.replace(\"UNKNOWN\",\"UNK.\", regex=False)\n",
    "    data2[parameter] = data2[parameter].str.replace(\"UNKNOWN\",\"UNK.\", regex=False)\n",
    "    \n",
    "    \n",
    "    x, y, z = \"RHOSTAR\", \"Q95\", \"TAUTH\"\n",
    "    \n",
    "    y_sp = (11, 20, 12)\n",
    "    if remSPH:\n",
    "        data1 = data1[~data1.TOK.isin(['START','MAST','NSTX'])]\n",
    "        data2 = data2[~data2.TOK.isin(['START','MAST','NSTX'])]\n",
    "        y_sp = (11, 25, 11)\n",
    "    \n",
    "    data1[\"colors\"] = data1[parameter].map(colors_dict) \n",
    "    data2[\"colors\"] = data2[parameter].map(colors_dict)\n",
    "    \n",
    "    fig = plt.figure(figsize=(13, 4.5))\n",
    "    ax1 = fig.add_subplot(121, projection='3d')\n",
    "    ax2 = fig.add_subplot(122, projection='3d')\n",
    "    \n",
    "    # Adjust subplot positions\n",
    "    fig.subplots_adjust(wspace=0.05)\n",
    "    \n",
    "    \n",
    "    scatter = ax1.scatter(data1[x], data1[y], data1[z], c=data1[\"colors\"].values)\n",
    "    ax1.set_xlabel(x, fontsize=11, labelpad=11)\n",
    "    ax1.set_ylabel(y, fontsize=y_sp[0], labelpad=y_sp[1])\n",
    "    ax1.set_zlabel(z, fontsize=11, rotation=90)  \n",
    "    ax1.tick_params(axis='x', labelsize=12)\n",
    "    ax1.tick_params(axis='y', labelsize=y_sp[2])\n",
    "    ax1.tick_params(axis='z', labelsize=12)\n",
    "    \n",
    "    ax1.set_xticks(ax1.get_xticks())\n",
    "    ax1.set_xticklabels(ax1.get_xticks(), rotation= -10)\n",
    "    \n",
    "    ax1.set_yticks(ax1.get_yticks())\n",
    "    ax1.set_yticklabels(ax1.get_yticks(), rotation=45)\n",
    "    ax1.view_init(elev=15, azim=rotation)\n",
    "\n",
    "\n",
    "    # GETTING THE SECOND PLOT\n",
    "    scatter = ax2.scatter(data2[x], data2[y], data2[z], c=data2[\"colors\"].values)\n",
    "    ax2.set_xlabel(x, fontsize=11, labelpad=11)\n",
    "    ax2.set_ylabel(y, fontsize=y_sp[0], labelpad=y_sp[1])\n",
    "    ax2.zaxis.set_label_text(z, fontsize=11, rotation=90)  \n",
    "    ax2.tick_params(axis='x', labelsize=12)\n",
    "    ax2.tick_params(axis='y', labelsize=y_sp[2])\n",
    "    ax2.tick_params(axis='z', labelsize=12)\n",
    "    \n",
    "    ax2.set_xticks(ax2.get_xticks())\n",
    "    ax2.set_xticklabels(ax2.get_xticks(), rotation= -10)\n",
    "    \n",
    "    ax2.set_yticks(ax2.get_yticks())\n",
    "    ax2.set_yticklabels(ax2.get_yticks(), rotation=45)\n",
    "    ax2.view_init(elev=15, azim=rotation)\n",
    "    \n",
    "    if stationary:\n",
    "        legend_elements = []\n",
    "        for category, color in colors_dict.items():\n",
    "            legend_elements.append(plt.Line2D([1], [1], marker='o', \n",
    "                                   color='w', label=category, markerfacecolor=color, markersize=7))\n",
    "        legend = ax1.legend(handles=legend_elements, frameon=False,\n",
    "                 loc='upper right', bbox_to_anchor=(1.3, 0.9), fontsize=9)\n",
    "        ax1.annotate(parameter, xy=(1.07, 0.9), xycoords='axes fraction',\n",
    "                 fontsize=10, fontweight='bold')\n",
    "    else:\n",
    "        for i in range(len(colors_dict)):\n",
    "            ax1.annotate(list(colors_dict.keys())[i], xy=(1.12, 0.84-0.05*i), xycoords='axes fraction',\n",
    "                 fontsize=12, fontweight='bold', color=list(colors_dict.values())[i])\n",
    "        ax1.annotate(parameter, xy=(1.1, 0.9), xycoords='axes fraction',\n",
    "                 fontsize=12)\n",
    "        \n",
    "    ax1.annotate(\"Decreasing\\n  $\\\\alpha_R \\\\sim 0.64$\", xy=(0.17, 0.87), xycoords='axes fraction',\n",
    "                 fontsize=12)\n",
    "    ax2.annotate(\"Unaffected\\n  $\\\\alpha_R \\\\sim 2.16$\", xy=(0.6, 0.86), xycoords='axes fraction',\n",
    "                 fontsize=12)\n",
    "    \n",
    "    ax1.set_zlim(min(min(data1[z]), min(data2[z]))*0.1, max(max(data1[z]), max(data2[z]))*1.1)\n",
    "    ax1.set_xlim(min(min(data1[x]), min(data2[x]))*0.1, max(max(data1[x]), max(data2[x]))*1.1)\n",
    "    ax1.set_ylim(min(min(data1[y]), min(data2[y]))*0.1, max(max(data1[y]), max(data2[y]))*1.1)\n",
    "    \n",
    "    ax2.set_zlim(min(min(data1[z]), min(data2[z]))*0.1, max(max(data1[z]), max(data2[z]))*1.1)\n",
    "    ax2.set_xlim(min(min(data1[x]), min(data2[x]))*0.1, max(max(data1[x]), max(data2[x]))*1.1)\n",
    "    ax2.set_ylim(min(min(data1[y]), min(data2[y]))*0.1, max(max(data1[y]), max(data2[y]))*1.1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #ax1.set_title(\"Decreasing\\n$\\\\alpha_R \\\\sim 0.64$\")\n",
    "    #ax2.set_title(\"Unaffected\\n$\\\\alpha_R \\\\sim 2.16$\")\n",
    "    \n",
    "    if saveFig:\n",
    "        plt.savefig(path + file_name, format=\"png\")\n",
    "        #plt.savefig(path + file_name, format=\"pdf\", dpi=800)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "ba50ee2a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#get_twods3D_plot_DB5(DB5, data, 340, \"LIMMAT\", stationary=False, saveFig=False, file_name=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "715ec4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in np.linspace(0,360, 360//2):\n",
    "    file_name = f\"GIF_images/image_{int(r)}.png\"\n",
    "    get_twods3D_plot_DB5(DB5, data, int(r), \"LIMMAT\", stationary=False, \n",
    "                         saveFig=True, file_name=file_name, remSPH=False\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "b91b939e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,z = \"NUSTAR\", \"RHOSTAR\", \"TAUTH\"\n",
    "\n",
    "image_folder = path+\"GIF_images/\"  # Path to the folder containing the images\n",
    "output_file = path+\"/GIFs/\"+f\"roLIM{x[0]}{y[0]}{z[0]}.gif\"  # Output file name\n",
    "\n",
    "# Get a list of PNG files in the folder\n",
    "image_files = [os.path.join(image_folder, file) for file in os.listdir(image_folder) if file.endswith('.png')]\n",
    "# Sort the image files by their numerical values in the filenames\n",
    "image_files.sort(key=lambda x: int(os.path.splitext(os.path.basename(x))[0].split('_')[-1]))\n",
    "\n",
    "# Save the images in the folder as an animated GIF\n",
    "imageio.mimsave(output_file, [imageio.imread(file) for file in image_files], fps=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "fc8721ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SS', 'C/SS', 'C', 'C/W', 'W', 'IN', 'IN/C', 'AL', 'UNKNOWN'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DB5[\"WALMAT\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "eaccf9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = DB5[DB5[\"LIMMAT\"].isin(['UNKNOWN'])]#.DIVMAT.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "f5ff3a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AUG'], dtype=object)"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_.TOK.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "3f2ba6da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BE'], dtype=object)"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DB5[DB5.TOK.isin(['JETILW'])].LIMMAT.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "bb5da803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1994', '1995', '1997', '1998', '1999', '2002', '2003', '2004',\n",
       "       '1990', '1996', '2000', '2001', '2012', '2013', '2014', '2015',\n",
       "       '2016'], dtype=object)"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1[data1[\"WALMAT\"].isin(['IN', 'IN/C'])].DATE.astype(str).apply(lambda x: x[:4]).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "613fce99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1994', '1996', '1997', '1998', '1999', '2004', '1989', '1990',\n",
       "       '1995', '2000', '2001', '2002', '2003', '2012', '2013', '2014',\n",
       "       '2015', '2016'], dtype=object)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2[data2[\"WALMAT\"].isin(['IN', 'IN/C'])].DATE.astype(str).apply(lambda x: x[:4]).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "ab097578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AUG, JT60U, MAST, NSTX, TFTR'"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"AUG', 'JT60U', 'MAST', 'NSTX', 'TFTR\".replace(\"'\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "b28013a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BE'], dtype=object)"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DB5[DB5.TOK.isin(['JETILW'])][\"LIMMAT\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "0693967b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.321"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(DB5[\"TAUTH\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "486ba6dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.356163227269"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(data1[data1.TOK.isin(['JETILW'])][\"TAUTH\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "29056325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.352657479902"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(data2[data2.TOK.isin(['JETILW'])][\"TAUTH\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "4731285d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9319"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(data1[\"TAUTH\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "6c558e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "824    D30MET\n",
       "Name: id, dtype: object"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1[data1[\"TAUTH\"] > 0.9][\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "37f64057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3121    LV6QYS\n",
       "Name: id, dtype: object"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DB5[DB5[\"TAUTH\"] > 1.3][\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "11d6f1e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ind</th>\n",
       "      <th>id</th>\n",
       "      <th>PHASE</th>\n",
       "      <th>TOK</th>\n",
       "      <th>IP</th>\n",
       "      <th>BT</th>\n",
       "      <th>NEL</th>\n",
       "      <th>PLTH</th>\n",
       "      <th>RGEO</th>\n",
       "      <th>KAREA</th>\n",
       "      <th>EPS</th>\n",
       "      <th>MEFF</th>\n",
       "      <th>TAUTH</th>\n",
       "      <th>DATE</th>\n",
       "      <th>SHOT</th>\n",
       "      <th>TIME</th>\n",
       "      <th>Q95</th>\n",
       "      <th>ZEFF</th>\n",
       "      <th>AMIN</th>\n",
       "      <th>VOL</th>\n",
       "      <th>POHM</th>\n",
       "      <th>PNBI</th>\n",
       "      <th>DWDIA</th>\n",
       "      <th>DWMHD</th>\n",
       "      <th>PICRH</th>\n",
       "      <th>PECRH</th>\n",
       "      <th>PL</th>\n",
       "      <th>PFLOSS</th>\n",
       "      <th>TAV</th>\n",
       "      <th>LCOULOMB</th>\n",
       "      <th>QCYL5</th>\n",
       "      <th>TAUBOHM</th>\n",
       "      <th>RHOSTAR</th>\n",
       "      <th>BETASTAR</th>\n",
       "      <th>NUSTAR</th>\n",
       "      <th>OMEGACYCL</th>\n",
       "      <th>IP_error</th>\n",
       "      <th>BT_error</th>\n",
       "      <th>NEL_error</th>\n",
       "      <th>PLTH_error</th>\n",
       "      <th>POHM_error</th>\n",
       "      <th>PNBI_error</th>\n",
       "      <th>DWDIA_error</th>\n",
       "      <th>DWMHD_error</th>\n",
       "      <th>PICRH_error</th>\n",
       "      <th>PECRH_error</th>\n",
       "      <th>PL_error</th>\n",
       "      <th>PFLOSS_error</th>\n",
       "      <th>RGEO_error</th>\n",
       "      <th>AMIN_error</th>\n",
       "      <th>EPS_error</th>\n",
       "      <th>VOL_error</th>\n",
       "      <th>KAREA_error</th>\n",
       "      <th>MEFF_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ind, id, PHASE, TOK, IP, BT, NEL, PLTH, RGEO, KAREA, EPS, MEFF, TAUTH, DATE, SHOT, TIME, Q95, ZEFF, AMIN, VOL, POHM, PNBI, DWDIA, DWMHD, PICRH, PECRH, PL, PFLOSS, TAV, LCOULOMB, QCYL5, TAUBOHM, RHOSTAR, BETASTAR, NUSTAR, OMEGACYCL, IP_error, BT_error, NEL_error, PLTH_error, POHM_error, PNBI_error, DWDIA_error, DWMHD_error, PICRH_error, PECRH_error, PL_error, PFLOSS_error, RGEO_error, AMIN_error, EPS_error, VOL_error, KAREA_error, MEFF_error]\n",
       "Index: []"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DB2[DB2.id.isin([\"D30MET\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596882f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
