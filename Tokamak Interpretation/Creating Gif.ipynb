{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8975f698",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aae237be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import tokamakTK\n",
    "from tokamakTK import get_ECT_regression, HUEOrder, get_pi_matrix, clean_numerical_data, MyCounter\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.colors as mcolors\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.subplots as plsp\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.rc('font',family = 'serif')\n",
    "path = \"../data/\"\n",
    "fig_path = \"../../../LATEX/Latex Images/\"\n",
    "\n",
    "coeffs = ['IP', 'BT', 'NEL', 'PLTH', 'RGEO', 'KAREA', 'EPS', 'MEFF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "657ad620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Subset that decrease alpha-R to 0.6357\n",
      "--------\n",
      "23.45% affected alpha_R\n",
      "76.55% did not affect alpha_R\n",
      "\n",
      "\n",
      "  Subset that decrease alpha-R to 0.9998\n",
      "--------\n",
      "9.88% affected alpha_R\n",
      "90.12% did not affect alpha_R\n",
      "\n",
      "\n",
      "  Subset given by Joseph Hall           \n",
      "--------\n",
      "18.46% affected alpha_R\n",
      "81.54% did not affect alpha_R\n"
     ]
    }
   ],
   "source": [
    "# Obtained from Optimization\n",
    "\n",
    "min_subset_ids_6357 = pd.read_csv(path+\"R_ids_alpha_0.6357.csv\")\n",
    "min_subset_ids_9998 = pd.read_csv(path+\"R_ids_alpha_0.9998.csv\")\n",
    "min_subset_ids_joe  = pd.read_csv(path+\"deviation_id.csv\")\n",
    "\n",
    "DB2 = pd.read_csv(path+\"DB2P8.csv\")\n",
    "DB5 = pd.read_csv(path+\"SELDB5_SVD.csv\", low_memory=False) \n",
    "\n",
    "# Setting ELMy Dataset\n",
    "DB5 = DB5[DB5[\"PHASE\"].isin(['HGELM', 'HSELM', 'HGELMH', 'HSELMH'])]\n",
    "\n",
    "# Removing Spherical TOKAMAKS\n",
    "#DB5 = DB5[~DB5[\"TOK\"].isin(['START','MAST','NSTX'])]\n",
    "\n",
    "# There is two shots from DB2P8 missing in DB5\n",
    "missing_shots = DB2[~DB2.id.isin( DB5.id.values )].reset_index(drop=True)\n",
    "DB5 = pd.concat([DB5, missing_shots], axis=0, ignore_index=True)\n",
    "\n",
    "# Labeling shots that had great impact in decreasing alpha_R\n",
    "DB5.insert(loc=2,column=\"label_6357\",value=[\"Unaffected\"]*len(DB5))\n",
    "DB5.loc[(DB5[DB5.id.isin(min_subset_ids_6357.id)].index), \"label_6357\"] = \"Decreasing\"\n",
    "\n",
    "DB5.insert(loc=2,column=\"label_9998\",value=[\"Unaffected\"]*len(DB5))\n",
    "DB5.loc[(DB5[DB5.id.isin(min_subset_ids_9998.id)].index), \"label_9998\"] = \"Decreasing\"\n",
    "\n",
    "DB5.insert(loc=2,column=\"label_joe\",value=[\"Unaffected\"]*len(DB5))\n",
    "DB5.loc[(DB5[DB5.id.isin(min_subset_ids_joe.id)].index), \"label_joe\"] = \"Decreasing\"\n",
    "\n",
    "DB5.insert(0, 'intercept', np.ones(len(DB5)))\n",
    "\n",
    "\n",
    "print(\n",
    "    \"  Subset that decrease alpha-R to 0.6357\\n--------\\n\" +\n",
    "    f\"{ round( (len(min_subset_ids_6357)/len(DB5))*100     ,2)  }% affected alpha_R\\n\" + \n",
    "    f\"{ round( (1 - len(min_subset_ids_6357)/len(DB5))*100 ,2)  }% did not affect alpha_R\" +\n",
    "    \"\\n\\n\\n  Subset that decrease alpha-R to 0.9998\\n--------\\n\" +\n",
    "    f\"{ round( (len(min_subset_ids_9998)/len(DB5))*100     ,2)  }% affected alpha_R\\n\" + \n",
    "    f\"{ round( (1 - len(min_subset_ids_9998)/len(DB5))*100 ,2)  }% did not affect alpha_R\"\n",
    "    \"\\n\\n\\n  Subset given by Joseph Hall           \\n--------\\n\" +\n",
    "    f\"{ round( (len(min_subset_ids_joe)/len(DB5))*100     ,2)  }% affected alpha_R\\n\" + \n",
    "    f\"{ round( (1 - len(min_subset_ids_joe)/len(DB5))*100 ,2)  }% did not affect alpha_R\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae9a6d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "amount = 20\n",
    "small_dataset = pd.read_csv(path+\"decreased_dataset_random_sampling_500_decreasing_points.csv\")\n",
    "samples = [f\"subset_{int(i)}\" for i in np.linspace(1,len(small_dataset.columns)-1,amount)]\n",
    "values = small_dataset[samples].describe().loc[\"min\"]\n",
    "indxs = [small_dataset[small_dataset[values.keys()[i]].isin([values.values[i]])].index[0] for i in range(amount)]\n",
    "\n",
    "\n",
    "info = pd.DataFrame([np.linspace(1,len(small_dataset.columns)-1,amount),small_dataset.loc[indxs][\"seed\"].values]).T\n",
    "info = info.rename(columns={0:\"sampling\", 1:\"seed\"})\n",
    "info[\"sampling\"] = info[\"sampling\"].astype(int)\n",
    "info[\"seed\"] = info[\"seed\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2c84fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB5_decreas_pts = pd.read_csv(path+\"decreasing_dataset_info.csv\")\n",
    "# Sampling on the decreasing points of the decreasing DS\n",
    "# If sampling is on \"decreased\": sampling on decreasing points in decreasing dataset (smaller alpha_R)\n",
    "# If sampling is on \"weights\": sampling on complete dataset only (highers alpha_R)\n",
    "IDs = [0]*amount\n",
    "for i in range(amount):\n",
    "    IDs[i] = DB5_decreas_pts.sample(n=info[\"sampling\"][i], weights='decreased', random_state=info[\"seed\"][i])\n",
    "    \n",
    "# Adding mine with alpha_R of approx 0.63\n",
    "IDs = IDs + [min_subset_ids_6357]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4992afe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = [DB5[DB5.id.isin(IDs[i].id.values) | DB5.id.isin(DB2.id.values)][coeffs+[\"TAUTH\"]] for i in range(amount+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4f7a123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.193381295547305,\n",
       " 1.8413459046650524,\n",
       " 1.6257035103070592,\n",
       " 1.4502291354609658,\n",
       " 1.3319700443067546,\n",
       " 1.2232065794708968,\n",
       " 1.1429833582859634,\n",
       " 1.0635431828948825,\n",
       " 0.9926216010787007,\n",
       " 0.9408375289922396,\n",
       " 0.8907058348274953,\n",
       " 0.8433327529157967,\n",
       " 0.8141162063836194,\n",
       " 0.7765526617447575,\n",
       " 0.7319295717685702,\n",
       " 0.7082993866348661,\n",
       " 0.6815782756548103,\n",
       " 0.6617309392275936,\n",
       " 0.6515977868422362,\n",
       " 0.6558006008429011,\n",
       " 0.6357571952782841]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[get_ECT_regression(DF[i]).params[\"RGEO\"] for i in range(len(DF))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7b7075",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36092acd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c8e040",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
