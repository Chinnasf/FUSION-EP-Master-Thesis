{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d6ef27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b27ef4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "import tokamakTK\n",
    "from tokamakTK import get_ECT_regression, HUEOrder, get_pi_matrix, clean_numerical_data, MyCounter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from PIL import Image\n",
    "#import imageio\n",
    "import imageio.v2 as imageio\n",
    "from matplotlib.lines import Line2D\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.colors as mcolors\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.subplots as plsp\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.rc('font',family = 'serif')\n",
    "path = \"../../data/\"\n",
    "fig_path = \"../../../../LATEX/Latex Images/\"\n",
    "\n",
    "coeffs = ['IP', 'BT', 'NEL', 'PLTH', 'RGEO', 'KAREA', 'EPS', 'MEFF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f7f3b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Subset that decrease alpha-R to 0.6357\n",
      "--------\n",
      "23.45% affected alpha_R\n",
      "76.55% did not affect alpha_R\n",
      "\n",
      "\n",
      "  Subset that decrease alpha-R to 0.9998\n",
      "--------\n",
      "9.88% affected alpha_R\n",
      "90.12% did not affect alpha_R\n",
      "\n",
      "\n",
      "  Subset given by Joseph Hall           \n",
      "--------\n",
      "18.46% affected alpha_R\n",
      "81.54% did not affect alpha_R\n"
     ]
    }
   ],
   "source": [
    "# Obtained from Optimization\n",
    "\n",
    "min_subset_ids_6357 = pd.read_csv(path+\"R_ids_alpha_0.6357.csv\")\n",
    "min_subset_ids_9998 = pd.read_csv(path+\"R_ids_alpha_0.9998.csv\")\n",
    "min_subset_ids_joe  = pd.read_csv(path+\"deviation_id.csv\")\n",
    "\n",
    "DB2 = pd.read_csv(path+\"DB2P8.csv\")\n",
    "DB5 = pd.read_csv(path+\"SELDB5_SVD.csv\", low_memory=False) \n",
    "\n",
    "# Setting ELMy Dataset\n",
    "DB5 = DB5[DB5[\"PHASE\"].isin(['HGELM', 'HSELM', 'HGELMH', 'HSELMH'])]\n",
    "\n",
    "# Removing Spherical TOKAMAKS\n",
    "#DB5 = DB5[~DB5[\"TOK\"].isin(['START','MAST','NSTX'])]\n",
    "\n",
    "# There is two shots from DB2P8 missing in DB5\n",
    "missing_shots = DB2[~DB2.id.isin( DB5.id.values )].reset_index(drop=True)\n",
    "DB5 = pd.concat([DB5, missing_shots], axis=0, ignore_index=True)\n",
    "\n",
    "# Labeling shots that had great impact in decreasing alpha_R\n",
    "DB5.insert(loc=2,column=\"label_6357\",value=[\"Unaffected\"]*len(DB5))\n",
    "DB5.loc[(DB5[DB5.id.isin(min_subset_ids_6357.id)].index), \"label_6357\"] = \"Decreasing\"\n",
    "\n",
    "DB5.insert(loc=2,column=\"label_9998\",value=[\"Unaffected\"]*len(DB5))\n",
    "DB5.loc[(DB5[DB5.id.isin(min_subset_ids_9998.id)].index), \"label_9998\"] = \"Decreasing\"\n",
    "\n",
    "DB5.insert(loc=2,column=\"label_joe\",value=[\"Unaffected\"]*len(DB5))\n",
    "DB5.loc[(DB5[DB5.id.isin(min_subset_ids_joe.id)].index), \"label_joe\"] = \"Decreasing\"\n",
    "\n",
    "DB5.insert(0, 'intercept', np.ones(len(DB5)))\n",
    "\n",
    "\n",
    "print(\n",
    "    \"  Subset that decrease alpha-R to 0.6357\\n--------\\n\" +\n",
    "    f\"{ round( (len(min_subset_ids_6357)/len(DB5))*100     ,2)  }% affected alpha_R\\n\" + \n",
    "    f\"{ round( (1 - len(min_subset_ids_6357)/len(DB5))*100 ,2)  }% did not affect alpha_R\" +\n",
    "    \"\\n\\n\\n  Subset that decrease alpha-R to 0.9998\\n--------\\n\" +\n",
    "    f\"{ round( (len(min_subset_ids_9998)/len(DB5))*100     ,2)  }% affected alpha_R\\n\" + \n",
    "    f\"{ round( (1 - len(min_subset_ids_9998)/len(DB5))*100 ,2)  }% did not affect alpha_R\"\n",
    "    \"\\n\\n\\n  Subset given by Joseph Hall           \\n--------\\n\" +\n",
    "    f\"{ round( (len(min_subset_ids_joe)/len(DB5))*100     ,2)  }% affected alpha_R\\n\" + \n",
    "    f\"{ round( (1 - len(min_subset_ids_joe)/len(DB5))*100 ,2)  }% did not affect alpha_R\"\n",
    ")\n",
    "\n",
    "DB5 = tokamakTK.clean_categorical_data(DB5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16cd334c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# amount: images that the gif will contain\n",
    "amount = 150\n",
    "\n",
    "small_dataset = pd.read_csv(path+\"decreased_dataset_random_sampling_500_decreasing_points.csv\")\n",
    "samples = [f\"subset_{int(i)}\" for i in np.linspace(1,len(small_dataset.columns)-1,amount)]\n",
    "values = small_dataset[samples].describe().loc[\"min\"]\n",
    "indxs = [small_dataset[small_dataset[values.keys()[i]].isin([values.values[i]])].index[0] for i in range(amount)]\n",
    "\n",
    "info = pd.DataFrame([np.linspace(1,len(small_dataset.columns)-1,amount),small_dataset.loc[indxs][\"seed\"].values]).T\n",
    "info = info.rename(columns={0:\"sampling\", 1:\"seed\"})\n",
    "info[\"sampling\"] = info[\"sampling\"].astype(int)\n",
    "info[\"seed\"] = info[\"seed\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "297f948b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB5_decreas_pts = pd.read_csv(path+\"decreasing_dataset_info.csv\")\n",
    "# Sampling on the decreasing points of the decreasing DS\n",
    "#    If sampling is on \"decreased\": sampling on decreasing points in decreasing dataset (smaller alpha_R)\n",
    "#    If sampling is on \"weights\": sampling on complete dataset only (highers alpha_R)\n",
    "IDs = [\n",
    "    DB5_decreas_pts.sample(n=info[\"sampling\"][i], \n",
    "                           weights='decreased', \n",
    "                           random_state=info[\"seed\"][i]) for i in range(amount)\n",
    "]\n",
    "    \n",
    "# Adding mine with alpha_R of approx 0.63\n",
    "IDs = IDs + [min_subset_ids_6357]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4611ddfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also serves as sanity check\n",
    "# ----------------------------------------\n",
    "DF = [DB5[DB5.id.isin(IDs[i].id.values) | DB5.id.isin(DB2.id.values)] for i in range(amount+1)]\n",
    "ALPHAs = [get_ECT_regression(DF[i]).params[\"RGEO\"] for i in range(len(DF))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "450c90c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_3D_plot_DB5_TOK(db5, i, indxs, saveFig = False, file_name=\"\"):\n",
    "    # Create a figure and a 3D axis\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    alpha = np.round(ALPHAs[i],2)\n",
    "    \n",
    "    data = db5.copy()\n",
    "    \n",
    "    HUE_ORDER, PX_ORDER = tokamakTK.get_colors_per_category(data)\n",
    "    category_colors = HUE_ORDER[\"TOK\"]\n",
    "\n",
    "    x,y,z = \"NUSTAR\", \"RHOSTAR\", \"BETASTAR\"\n",
    "    data[\"colors\"] = data[\"TOK\"].map(category_colors)\n",
    "\n",
    "    # Plot the data points\n",
    "    scatter = ax.scatter(data[x], data[y], data[z], c=data[\"colors\"].values)\n",
    "    ax.set_xlabel(x, fontsize=12, labelpad=10)\n",
    "    ax.set_ylabel(y, fontsize=12, labelpad=10)\n",
    "    ax.set_zlabel(z, fontsize=12, rotation=0)  # Increase the labelpad to make it more visible\n",
    "    \n",
    "    # Add a legend\n",
    "    legend_elements = []\n",
    "    for category, color in category_colors.items():\n",
    "        legend_elements.append(plt.Line2D([0], [0], marker='o', \n",
    "                                          color='w', label=category, markerfacecolor=color, markersize=7))\n",
    "\n",
    "    legend = ax.legend(handles=legend_elements, frameon=False,\n",
    "                       loc='upper right', bbox_to_anchor=(1.2, 0.9), fontsize=8)\n",
    "\n",
    "\n",
    "    ax.tick_params(axis='x', labelsize=12)  # x-axis ticks\n",
    "    ax.tick_params(axis='y', labelsize=12)  # y-axis ticks\n",
    "    ax.tick_params(axis='z', labelsize=12)  # z-axis ticks\n",
    "\n",
    "    #fig.set_size_inches(16,13) \n",
    "    ax.view_init(elev=25, azim=23)\n",
    "\n",
    "    \n",
    "    if saveFig:\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(path+file_name, format=\"png\", dpi=800)\n",
    "        #plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88e98b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_3D_gif_DB5(db5, i, indxs, saveFig = False, file_name=\"\", removeSPH=False):\n",
    "    # Create a figure and a 3D axis\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    alpha = np.round(ALPHAs[i],2)\n",
    "    \n",
    "    data = db5.copy()\n",
    "    \n",
    "    if removeSPH:\n",
    "        data = data[~data.TOK.isin(['START','MAST','NSTX'])]\n",
    "    \n",
    "\n",
    "    x,y,z = \"NUSTAR\", \"RHOSTAR\", \"BETASTAR\"\n",
    "    data[\"colors\"] = [\"black\"]*len(data)\n",
    "    data.loc[(data[data.id.isin(indxs.id.values)].index), \"colors\"] = \"red\"\n",
    "\n",
    "    # Plot the data points\n",
    "    ax.scatter(data[x], data[y], data[z], c=data[\"colors\"].values)\n",
    "    ax.set_xlabel(x, fontsize=12, labelpad=10)\n",
    "    ax.set_ylabel(y, fontsize=12, labelpad=20)\n",
    "    ax.set_zlabel(z, fontsize=12,  rotation=90)  \n",
    "    ax.tick_params(axis='x', labelsize=10)\n",
    "    ax.tick_params(axis='y', labelsize=10)\n",
    "    ax.tick_params(axis='z', labelsize=10)\n",
    "    \n",
    "    ax.set_yticks(ax.get_yticks())\n",
    "    ax.set_yticklabels(ax.get_yticks(), rotation=45)\n",
    "\n",
    "    ax.view_init(elev=17, azim=32) \n",
    "    \n",
    "    ax.text(4.3, 0, max(data[z]*1.4), 'Decreasing', color='red', fontsize=15)\n",
    "    ax.text(4.3, 0, max(data[z]*1.5), 'Unaffected', color='black', fontsize=15)\n",
    "    ax.text(4.29, 0, max(data[z]*1.6), f\"$\\\\alpha_R \\\\sim$ {alpha}\", color='black', fontsize=17)\n",
    "    \n",
    "    if saveFig:\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(path+file_name)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83c91491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMEMBER TO DELETE THE test.png\n",
    "#get_3D_plot_DB5_TOK(DB5, 15, IDs[15], True, \"TOK/3D_BETASTAR_NUSTAR_RHOSTAR.png\")\n",
    "#get_3D_gif_DB5(DB5, 15, min_subset_ids_joe, True, \"test\", removeSPH=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149f6d96",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, indxs in enumerate(IDs):\n",
    "    file_name = f\"GIF_images/image_{i}.png\"\n",
    "    get_3D_gif_DB5(DB5, i, indxs, True, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433322dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HEAVY GIF (amount = 750)\n",
    "x,y,z = \"NUSTAR\", \"RHOSTAR\", \"BETASTAR\"\n",
    "\n",
    "image_folder = path+\"GIF_images/\"  # Path to the folder containing the images\n",
    "output_file = f'change_in_{x}_{y}_{z}.gif'  # Output file name\n",
    "\n",
    "# Get a list of PNG files in the folder\n",
    "image_files = [os.path.join(image_folder, file) for file in os.listdir(image_folder) if file.endswith('.png')]\n",
    "# Sort the image files by their numerical values in the filenames\n",
    "image_files.sort(key=lambda x: int(os.path.splitext(os.path.basename(x))[0].split('_')[-1]))\n",
    "\n",
    "# Save the images in the folder as an animated GIF\n",
    "imageio.mimsave(output_file, [imageio.imread(file) for file in image_files], fps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f04114",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069d562b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d7db3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe2817c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
