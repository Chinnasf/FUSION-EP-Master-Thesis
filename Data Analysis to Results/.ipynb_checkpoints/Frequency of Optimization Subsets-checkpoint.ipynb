{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f12b0996",
   "metadata": {},
   "source": [
    "# Frequency in IDs that Decreases $\\alpha_R$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a7055cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from IPython.core.debugger import Pdb #Pdb().set_trace()\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "coeffs = ['IP', 'BT', 'NEL', 'PLTH', 'RGEO', 'KAREA', 'EPS', 'MEFF']\n",
    "path = \"../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b991173",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sampling = pd.read_csv(path + \"decreased_dataset_random_sampling_500_decreasing_points.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06cfd567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After sampling size of 36, all alpha-R in ramdon sampling will be < 2.121\n"
     ]
    }
   ],
   "source": [
    "df = random_sampling.describe().T\n",
    "\n",
    "threshold = 2\n",
    "min_subset_size = int(df[df['min'] < threshold].index[0].split(\"_\")[-1])\n",
    "\n",
    "amounts = random_sampling.columns[min_subset_size - 1:]\n",
    "max_alpha_R = round((random_sampling[amounts].describe().T)[\"max\"].sort_values().iloc[-2], 4)\n",
    "\n",
    "random_sampling = random_sampling[random_sampling.columns[min_subset_size-1:]]\n",
    "print(f\"After sampling size of {min_subset_size}, all alpha-R in ramdon sampling will be < {max_alpha_R}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10c1f8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB2P8 = pd.read_csv(path+\"DB2P8.csv\")\n",
    "DB5 = pd.read_csv(path+\"DB5.csv\")\n",
    "DB2 = DB2P8[DB5.columns] # Because DB2P8 has more columns than DB5\n",
    "\n",
    "# There is two shots from DB2P8 missing in DB5\n",
    "missing_shots = DB2[~DB2.id.isin( DB5.id.values )].reset_index(drop=True)\n",
    "DB5 = pd.concat([DB5, missing_shots], axis=0, ignore_index=True)\n",
    "\n",
    "decreasing_ds = pd.read_csv(path+\"decreasing_dataset_info.csv\")\n",
    "# Re-Introduce Dataset | What's new in DB5 that decreases Î±R\n",
    "R_dec = DB5[DB5.id.isin(decreasing_ds.id)].reset_index(drop=True) \n",
    "\n",
    "R_dec[\"decreasing_pts\"] = R_dec[\"id\"].map(dict(zip(decreasing_ds.id, decreasing_ds.decreased)))\n",
    "R_dec[\"decreasing_weights\"] = R_dec[\"id\"].map(dict(zip(decreasing_ds.id, decreasing_ds.weights)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f080acaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regression(_R):\n",
    "    \"\"\"\n",
    "    ASSUMING DATA IS ***NOT*** GIVEN IN LOG-SCALE\n",
    "    \"\"\"\n",
    "    data = pd.concat([DB2, _R],\n",
    "                     axis=0, \n",
    "                     ignore_index=True\n",
    "                    )\n",
    "    Y_ = data[[\"TAUTH\"]].apply(np.log).to_numpy()\n",
    "    # Adding a column for the intercept\n",
    "    _df = data[coeffs].apply(np.abs).apply(np.log)\n",
    "    _df.insert(\n",
    "        loc = 0, \n",
    "        column = \"intercept\", \n",
    "        value = np.ones(len(_df))\n",
    "    )\n",
    "    X_ = _df.to_numpy()\n",
    "    n_, p_ = X_.shape\n",
    "    model = sm.OLS(Y_,X_)\n",
    "    regression = model.fit()\n",
    "    return data, regression, (n_,p_)\n",
    "\n",
    "# Getting regression of DB2P8 only. \n",
    "empty_R = R_dec[R_dec.id.isin([0])]\n",
    "regression_DB2= get_regression( empty_R )[1]\n",
    "#regression_DB2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f16a0233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subset_36</th>\n",
       "      <th>subset_37</th>\n",
       "      <th>subset_38</th>\n",
       "      <th>subset_39</th>\n",
       "      <th>subset_40</th>\n",
       "      <th>subset_41</th>\n",
       "      <th>subset_42</th>\n",
       "      <th>subset_43</th>\n",
       "      <th>subset_44</th>\n",
       "      <th>subset_45</th>\n",
       "      <th>subset_46</th>\n",
       "      <th>subset_47</th>\n",
       "      <th>subset_48</th>\n",
       "      <th>subset_49</th>\n",
       "      <th>subset_50</th>\n",
       "      <th>subset_51</th>\n",
       "      <th>subset_52</th>\n",
       "      <th>subset_53</th>\n",
       "      <th>subset_54</th>\n",
       "      <th>subset_55</th>\n",
       "      <th>seed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.028032</td>\n",
       "      <td>2.025356</td>\n",
       "      <td>2.022786</td>\n",
       "      <td>2.013472</td>\n",
       "      <td>2.008839</td>\n",
       "      <td>2.005766</td>\n",
       "      <td>1.995925</td>\n",
       "      <td>1.991798</td>\n",
       "      <td>1.990475</td>\n",
       "      <td>1.984224</td>\n",
       "      <td>1.982490</td>\n",
       "      <td>1.975997</td>\n",
       "      <td>1.975889</td>\n",
       "      <td>1.973791</td>\n",
       "      <td>1.972872</td>\n",
       "      <td>1.968390</td>\n",
       "      <td>1.952411</td>\n",
       "      <td>1.951256</td>\n",
       "      <td>1.947754</td>\n",
       "      <td>1.946707</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.017517</td>\n",
       "      <td>2.015939</td>\n",
       "      <td>2.014711</td>\n",
       "      <td>2.005658</td>\n",
       "      <td>2.003267</td>\n",
       "      <td>1.999027</td>\n",
       "      <td>1.994245</td>\n",
       "      <td>1.986620</td>\n",
       "      <td>1.990786</td>\n",
       "      <td>1.990227</td>\n",
       "      <td>1.985166</td>\n",
       "      <td>1.978431</td>\n",
       "      <td>1.976444</td>\n",
       "      <td>1.965059</td>\n",
       "      <td>1.971155</td>\n",
       "      <td>1.968623</td>\n",
       "      <td>1.967685</td>\n",
       "      <td>1.965292</td>\n",
       "      <td>1.965124</td>\n",
       "      <td>1.953086</td>\n",
       "      <td>284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.090829</td>\n",
       "      <td>2.088937</td>\n",
       "      <td>2.086592</td>\n",
       "      <td>2.081695</td>\n",
       "      <td>2.078387</td>\n",
       "      <td>2.073037</td>\n",
       "      <td>2.067668</td>\n",
       "      <td>2.061368</td>\n",
       "      <td>2.062682</td>\n",
       "      <td>2.059827</td>\n",
       "      <td>2.052184</td>\n",
       "      <td>2.050565</td>\n",
       "      <td>2.050083</td>\n",
       "      <td>2.048354</td>\n",
       "      <td>2.030702</td>\n",
       "      <td>2.029305</td>\n",
       "      <td>2.027858</td>\n",
       "      <td>2.026159</td>\n",
       "      <td>2.024165</td>\n",
       "      <td>2.019683</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.065293</td>\n",
       "      <td>2.054109</td>\n",
       "      <td>2.050571</td>\n",
       "      <td>2.044874</td>\n",
       "      <td>2.043964</td>\n",
       "      <td>2.042679</td>\n",
       "      <td>2.040852</td>\n",
       "      <td>2.040840</td>\n",
       "      <td>2.040281</td>\n",
       "      <td>2.039004</td>\n",
       "      <td>2.037557</td>\n",
       "      <td>2.036122</td>\n",
       "      <td>2.035300</td>\n",
       "      <td>2.032666</td>\n",
       "      <td>2.033159</td>\n",
       "      <td>2.027562</td>\n",
       "      <td>2.020492</td>\n",
       "      <td>2.019188</td>\n",
       "      <td>2.017046</td>\n",
       "      <td>2.012359</td>\n",
       "      <td>426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.044564</td>\n",
       "      <td>2.041909</td>\n",
       "      <td>2.034898</td>\n",
       "      <td>2.029114</td>\n",
       "      <td>2.021986</td>\n",
       "      <td>2.016497</td>\n",
       "      <td>2.016938</td>\n",
       "      <td>2.012534</td>\n",
       "      <td>2.008716</td>\n",
       "      <td>2.003959</td>\n",
       "      <td>2.000021</td>\n",
       "      <td>1.999046</td>\n",
       "      <td>1.995700</td>\n",
       "      <td>1.991947</td>\n",
       "      <td>1.990510</td>\n",
       "      <td>1.987422</td>\n",
       "      <td>1.984696</td>\n",
       "      <td>1.983083</td>\n",
       "      <td>1.976380</td>\n",
       "      <td>1.964109</td>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>2.068017</td>\n",
       "      <td>2.060377</td>\n",
       "      <td>2.057548</td>\n",
       "      <td>2.051040</td>\n",
       "      <td>2.048085</td>\n",
       "      <td>2.042133</td>\n",
       "      <td>2.041262</td>\n",
       "      <td>2.035741</td>\n",
       "      <td>2.030439</td>\n",
       "      <td>2.027146</td>\n",
       "      <td>2.022091</td>\n",
       "      <td>2.020469</td>\n",
       "      <td>2.019316</td>\n",
       "      <td>2.018648</td>\n",
       "      <td>2.013816</td>\n",
       "      <td>2.010584</td>\n",
       "      <td>2.005482</td>\n",
       "      <td>2.002165</td>\n",
       "      <td>1.997429</td>\n",
       "      <td>1.992888</td>\n",
       "      <td>35358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>2.049111</td>\n",
       "      <td>2.044571</td>\n",
       "      <td>2.043356</td>\n",
       "      <td>2.040397</td>\n",
       "      <td>2.037112</td>\n",
       "      <td>2.033909</td>\n",
       "      <td>2.031872</td>\n",
       "      <td>2.031171</td>\n",
       "      <td>2.019120</td>\n",
       "      <td>2.017292</td>\n",
       "      <td>2.014876</td>\n",
       "      <td>2.010789</td>\n",
       "      <td>2.009802</td>\n",
       "      <td>2.005812</td>\n",
       "      <td>2.001701</td>\n",
       "      <td>1.996424</td>\n",
       "      <td>1.995816</td>\n",
       "      <td>1.992973</td>\n",
       "      <td>1.987802</td>\n",
       "      <td>1.979778</td>\n",
       "      <td>35429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>2.065951</td>\n",
       "      <td>2.063133</td>\n",
       "      <td>2.059942</td>\n",
       "      <td>2.047397</td>\n",
       "      <td>2.044678</td>\n",
       "      <td>2.037075</td>\n",
       "      <td>2.035657</td>\n",
       "      <td>2.033118</td>\n",
       "      <td>2.027810</td>\n",
       "      <td>2.016863</td>\n",
       "      <td>2.012884</td>\n",
       "      <td>2.012402</td>\n",
       "      <td>2.010263</td>\n",
       "      <td>2.008915</td>\n",
       "      <td>2.004864</td>\n",
       "      <td>1.998029</td>\n",
       "      <td>1.999239</td>\n",
       "      <td>1.993409</td>\n",
       "      <td>1.984331</td>\n",
       "      <td>1.981409</td>\n",
       "      <td>35500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>2.042431</td>\n",
       "      <td>2.040236</td>\n",
       "      <td>2.021563</td>\n",
       "      <td>2.012045</td>\n",
       "      <td>2.008281</td>\n",
       "      <td>2.005584</td>\n",
       "      <td>2.003353</td>\n",
       "      <td>1.995537</td>\n",
       "      <td>1.992676</td>\n",
       "      <td>1.989637</td>\n",
       "      <td>1.985958</td>\n",
       "      <td>1.977652</td>\n",
       "      <td>1.973851</td>\n",
       "      <td>1.970594</td>\n",
       "      <td>1.969378</td>\n",
       "      <td>1.968328</td>\n",
       "      <td>1.965456</td>\n",
       "      <td>1.961027</td>\n",
       "      <td>1.958134</td>\n",
       "      <td>1.953599</td>\n",
       "      <td>35571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>2.079452</td>\n",
       "      <td>2.077373</td>\n",
       "      <td>2.063659</td>\n",
       "      <td>2.059203</td>\n",
       "      <td>2.058613</td>\n",
       "      <td>2.054887</td>\n",
       "      <td>2.050047</td>\n",
       "      <td>2.040400</td>\n",
       "      <td>2.029389</td>\n",
       "      <td>2.026454</td>\n",
       "      <td>2.020361</td>\n",
       "      <td>2.016130</td>\n",
       "      <td>2.010484</td>\n",
       "      <td>2.004464</td>\n",
       "      <td>2.003693</td>\n",
       "      <td>1.998516</td>\n",
       "      <td>1.994592</td>\n",
       "      <td>1.993224</td>\n",
       "      <td>1.987703</td>\n",
       "      <td>1.985029</td>\n",
       "      <td>35642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     subset_36  subset_37  subset_38  subset_39  subset_40  subset_41  \\\n",
       "0     2.028032   2.025356   2.022786   2.013472   2.008839   2.005766   \n",
       "1     2.017517   2.015939   2.014711   2.005658   2.003267   1.999027   \n",
       "2     2.090829   2.088937   2.086592   2.081695   2.078387   2.073037   \n",
       "3     2.065293   2.054109   2.050571   2.044874   2.043964   2.042679   \n",
       "4     2.044564   2.041909   2.034898   2.029114   2.021986   2.016497   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "495   2.068017   2.060377   2.057548   2.051040   2.048085   2.042133   \n",
       "496   2.049111   2.044571   2.043356   2.040397   2.037112   2.033909   \n",
       "497   2.065951   2.063133   2.059942   2.047397   2.044678   2.037075   \n",
       "498   2.042431   2.040236   2.021563   2.012045   2.008281   2.005584   \n",
       "499   2.079452   2.077373   2.063659   2.059203   2.058613   2.054887   \n",
       "\n",
       "     subset_42  subset_43  subset_44  subset_45  subset_46  subset_47  \\\n",
       "0     1.995925   1.991798   1.990475   1.984224   1.982490   1.975997   \n",
       "1     1.994245   1.986620   1.990786   1.990227   1.985166   1.978431   \n",
       "2     2.067668   2.061368   2.062682   2.059827   2.052184   2.050565   \n",
       "3     2.040852   2.040840   2.040281   2.039004   2.037557   2.036122   \n",
       "4     2.016938   2.012534   2.008716   2.003959   2.000021   1.999046   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "495   2.041262   2.035741   2.030439   2.027146   2.022091   2.020469   \n",
       "496   2.031872   2.031171   2.019120   2.017292   2.014876   2.010789   \n",
       "497   2.035657   2.033118   2.027810   2.016863   2.012884   2.012402   \n",
       "498   2.003353   1.995537   1.992676   1.989637   1.985958   1.977652   \n",
       "499   2.050047   2.040400   2.029389   2.026454   2.020361   2.016130   \n",
       "\n",
       "     subset_48  subset_49  subset_50  subset_51  subset_52  subset_53  \\\n",
       "0     1.975889   1.973791   1.972872   1.968390   1.952411   1.951256   \n",
       "1     1.976444   1.965059   1.971155   1.968623   1.967685   1.965292   \n",
       "2     2.050083   2.048354   2.030702   2.029305   2.027858   2.026159   \n",
       "3     2.035300   2.032666   2.033159   2.027562   2.020492   2.019188   \n",
       "4     1.995700   1.991947   1.990510   1.987422   1.984696   1.983083   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "495   2.019316   2.018648   2.013816   2.010584   2.005482   2.002165   \n",
       "496   2.009802   2.005812   2.001701   1.996424   1.995816   1.992973   \n",
       "497   2.010263   2.008915   2.004864   1.998029   1.999239   1.993409   \n",
       "498   1.973851   1.970594   1.969378   1.968328   1.965456   1.961027   \n",
       "499   2.010484   2.004464   2.003693   1.998516   1.994592   1.993224   \n",
       "\n",
       "     subset_54  subset_55   seed  \n",
       "0     1.947754   1.946707    213  \n",
       "1     1.965124   1.953086    284  \n",
       "2     2.024165   2.019683    355  \n",
       "3     2.017046   2.012359    426  \n",
       "4     1.976380   1.964109    497  \n",
       "..         ...        ...    ...  \n",
       "495   1.997429   1.992888  35358  \n",
       "496   1.987802   1.979778  35429  \n",
       "497   1.984331   1.981409  35500  \n",
       "498   1.958134   1.953599  35571  \n",
       "499   1.987703   1.985029  35642  \n",
       "\n",
       "[500 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_sampling = random_sampling[list(random_sampling.columns[:20]) + [\"seed\"]]\n",
    "random_sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76aa0aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_num_of_sampling = len(random_sampling.columns[:-1])\n",
    "seeds = random_sampling.seed.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abc36446",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"IDs/alpha_two/\"\n",
    "\n",
    "for i,s in enumerate(seeds):\n",
    "    for j in range(total_num_of_sampling):\n",
    "        amount = int(random_sampling.columns[j].split(\"_\")[-1])\n",
    "        R_sampled = R_dec.sample(n=amount, weights='decreasing_pts', random_state=s)\n",
    "        # Getting diverse samples for alpha_R below 0.9\n",
    "        alpha_R = get_regression( R_sampled )[1].params[5]\n",
    "        IDs =  R_sampled.id.values\n",
    "\n",
    "        with open(path+folder+f'IDs_alpha_({i}_{j})_{alpha_R}.csv', mode='w', newline='') as csv_file:\n",
    "            # create a CSV writer object with the '|' delimiter\n",
    "            writer = csv.writer(csv_file, delimiter='|')\n",
    "            # write the header row\n",
    "            writer.writerow(['ids'])\n",
    "\n",
    "            for id_ in IDs:\n",
    "                writer.writerow([id_])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9697f4d1",
   "metadata": {},
   "source": [
    "```python\n",
    "folder = \"IDs/alpha_two/\"\n",
    "\n",
    "for i,s in enumerate(seeds):\n",
    "    for j in range(total_num_of_sampling):\n",
    "        amount = int(random_sampling.columns[j].split(\"_\")[-1])\n",
    "        R_sampled = R_dec.sample(n=amount, weights='decreasing_pts', random_state=s)\n",
    "        # Getting diverse samples for alpha_R below 0.9\n",
    "        alpha_R = get_regression( R_sampled )[1].params[5]\n",
    "        IDs =  R_sampled.id.values\n",
    "\n",
    "        with open(path+folder+f'IDs_alpha_({i}_{j})_{alpha_R}.csv', mode='w', newline='') as csv_file:\n",
    "            # create a CSV writer object with the '|' delimiter\n",
    "            writer = csv.writer(csv_file, delimiter='|')\n",
    "            # write the header row\n",
    "            writer.writerow(['ids'])\n",
    "\n",
    "            for id_ in IDs:\n",
    "                writer.writerow([id_])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a27d559",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "search_strings = decreasing_ds.id.values\n",
    "string_counts = {string: 0 for string in search_strings}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a1bed0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through each file in the folder\n",
    "for filename in os.listdir(path+folder):\n",
    "    file_path = os.path.join(path+folder, filename)\n",
    "    # load the CSV file into a pandas DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "    # count the occurrences of each search string in the DataFrame\n",
    "    for string in search_strings:\n",
    "        count = df[df['ids'].str.contains(string, na=False)].shape[0]\n",
    "        string_counts[string] += count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3aa99d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = pd.DataFrame([string_counts.keys(), string_counts.values()]).T.rename(columns={0:\"id\", 1:\"frequency\"})\n",
    "df_.to_csv(path+folder+\"id_vs_frequency_decreasing_ds_two.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f830afa",
   "metadata": {},
   "source": [
    "```Python\n",
    "# loop through each file in the folder\n",
    "for filename in os.listdir(path+folder):\n",
    "    file_path = os.path.join(path+folder, filename)\n",
    "    # load the CSV file into a pandas DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "    # count the occurrences of each search string in the DataFrame\n",
    "    for string in search_strings:\n",
    "        count = df[df['ids'].str.contains(string, na=False)].shape[0]\n",
    "        string_counts[string] += count\n",
    "\n",
    "#df_ = pd.DataFrame([string_counts.keys(), string_counts.values()]).T.rename(columns={0:\"id\", 1:\"frequency\"})\n",
    "#df_.to_csv(path+folder+\"id_vs_frequency_decreasing_ds_ones.csv\", index=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fdc721",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c2f8f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = pd.read_csv(path+folder+ \"id_vs_frequency_decreasing_ds_two.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4db829f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([289, 234, 231, 292, 314, 493, 343, 335, 339, 317, 148, 466, 329,\n",
       "       351, 203, 344, 227, 288, 373, 401, 336, 330, 278, 341, 408, 319,\n",
       "       356,   0, 299, 280, 321, 236, 380, 275, 417, 272, 326, 178, 323,\n",
       "       353, 233, 359, 240, 128, 253, 352, 340, 310, 286, 298, 181, 209,\n",
       "       237, 217, 443, 207, 220, 453, 242, 365, 327, 316, 235, 261, 333,\n",
       "       267, 290, 229, 247, 251, 364, 271, 376, 303, 306, 302, 412, 442,\n",
       "       252, 295, 239, 371, 218, 394, 249, 258, 384, 159, 381, 459, 248,\n",
       "       273, 414, 338, 270, 345, 150, 483, 484, 287, 349, 435, 211, 283,\n",
       "       254, 320, 418, 250, 350, 164, 308, 262, 195, 156, 141, 232, 468,\n",
       "       451, 196, 188, 294, 172, 269, 226, 225, 214, 291, 410, 360, 361,\n",
       "       311, 354, 374, 367, 346, 296, 391, 385, 415, 399, 246, 494, 263,\n",
       "       213, 313, 212, 281, 210, 265, 304, 428, 427, 177, 200, 282, 322,\n",
       "       325, 245, 382, 293, 301, 279, 219, 404, 244, 334, 366, 347, 198,\n",
       "       439, 309, 154, 368, 307, 450, 331, 379, 348, 328, 312, 192, 277,\n",
       "       268, 370, 276, 257, 264, 369, 260, 168, 383, 363, 266, 409, 228,\n",
       "       165, 422, 395, 426, 315, 423, 204, 433, 324, 166, 446, 238, 318,\n",
       "       355, 357, 284, 377, 256, 461, 152, 243, 191, 413, 514, 305, 189,\n",
       "       445, 222, 485, 216, 375, 431, 467, 223, 285, 389, 505, 402, 358,\n",
       "       411, 406, 259, 400, 185, 151, 205, 230, 387, 386, 199, 392, 362,\n",
       "       337, 332, 255, 342, 197, 149, 157, 448, 241, 300, 407, 420, 274,\n",
       "       495, 378, 539, 396, 129, 190, 194, 221, 432, 297, 397, 100, 474,\n",
       "       145, 182, 186, 388, 173, 202, 469, 424, 416, 458, 175, 180, 491,\n",
       "       224, 193,  87, 176, 206, 372, 133, 475, 487, 146, 398, 421, 201,\n",
       "       507, 460, 429, 122, 434, 447, 478, 134, 531, 174, 438, 208, 473,\n",
       "       535, 138, 440, 187, 184, 454, 471, 419, 118, 520])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_[df_.frequency < 9000][\"frequency\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9f14557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AEWB71</td>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UAAXGA</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53LSPJ</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FLO8WI</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TKCDLW</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2533</th>\n",
       "      <td>G8OILS</td>\n",
       "      <td>421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2537</th>\n",
       "      <td>ST5FL8</td>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2538</th>\n",
       "      <td>G8PHEQ</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2539</th>\n",
       "      <td>K3O76W</td>\n",
       "      <td>335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2540</th>\n",
       "      <td>ZD6MZS</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1486 rows Ã 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  frequency\n",
       "0     AEWB71        289\n",
       "1     UAAXGA        234\n",
       "2     53LSPJ        231\n",
       "3     FLO8WI        292\n",
       "4     TKCDLW        314\n",
       "...      ...        ...\n",
       "2533  G8OILS        421\n",
       "2537  ST5FL8        286\n",
       "2538  G8PHEQ        276\n",
       "2539  K3O76W        335\n",
       "2540  ZD6MZS        320\n",
       "\n",
       "[1486 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_[df_.frequency > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1007fad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "539"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(df_[\"frequency\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d5c8580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "401"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(df_[df_.frequency > 400][\"frequency\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac52939b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.968</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.968</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   5097.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 29 Mar 2023</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:48:23</td>     <th>  Log-Likelihood:    </th> <td>  492.91</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1355</td>      <th>  AIC:               </th> <td>  -967.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1346</td>      <th>  BIC:               </th> <td>  -920.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     8</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   -2.8747</td> <td>    0.048</td> <td>  -59.379</td> <td> 0.000</td> <td>   -2.970</td> <td>   -2.780</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.8583</td> <td>    0.026</td> <td>   32.760</td> <td> 0.000</td> <td>    0.807</td> <td>    0.910</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.2689</td> <td>    0.028</td> <td>    9.663</td> <td> 0.000</td> <td>    0.214</td> <td>    0.324</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.3515</td> <td>    0.020</td> <td>   17.542</td> <td> 0.000</td> <td>    0.312</td> <td>    0.391</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -0.6442</td> <td>    0.013</td> <td>  -47.730</td> <td> 0.000</td> <td>   -0.671</td> <td>   -0.618</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    1.9930</td> <td>    0.050</td> <td>   40.217</td> <td> 0.000</td> <td>    1.896</td> <td>    2.090</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    0.3335</td> <td>    0.042</td> <td>    7.910</td> <td> 0.000</td> <td>    0.251</td> <td>    0.416</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    0.4439</td> <td>    0.053</td> <td>    8.396</td> <td> 0.000</td> <td>    0.340</td> <td>    0.548</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>    0.2019</td> <td>    0.031</td> <td>    6.461</td> <td> 0.000</td> <td>    0.141</td> <td>    0.263</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>49.806</td> <th>  Durbin-Watson:     </th> <td>   0.811</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  94.533</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.258</td> <th>  Prob(JB):          </th> <td>2.97e-21</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.187</td> <th>  Cond. No.          </th> <td>    49.2</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.968\n",
       "Model:                            OLS   Adj. R-squared:                  0.968\n",
       "Method:                 Least Squares   F-statistic:                     5097.\n",
       "Date:                Wed, 29 Mar 2023   Prob (F-statistic):               0.00\n",
       "Time:                        19:48:23   Log-Likelihood:                 492.91\n",
       "No. Observations:                1355   AIC:                            -967.8\n",
       "Df Residuals:                    1346   BIC:                            -920.9\n",
       "Df Model:                           8                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         -2.8747      0.048    -59.379      0.000      -2.970      -2.780\n",
       "x1             0.8583      0.026     32.760      0.000       0.807       0.910\n",
       "x2             0.2689      0.028      9.663      0.000       0.214       0.324\n",
       "x3             0.3515      0.020     17.542      0.000       0.312       0.391\n",
       "x4            -0.6442      0.013    -47.730      0.000      -0.671      -0.618\n",
       "x5             1.9930      0.050     40.217      0.000       1.896       2.090\n",
       "x6             0.3335      0.042      7.910      0.000       0.251       0.416\n",
       "x7             0.4439      0.053      8.396      0.000       0.340       0.548\n",
       "x8             0.2019      0.031      6.461      0.000       0.141       0.263\n",
       "==============================================================================\n",
       "Omnibus:                       49.806   Durbin-Watson:                   0.811\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               94.533\n",
       "Skew:                          -0.258   Prob(JB):                     2.97e-21\n",
       "Kurtosis:                       4.187   Cond. No.                         49.2\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Claramente no es el alpha_R m'as bajo ni el subset mas corto\n",
    "# Pero es con el que mejor aprende el algoritmo de clasificacion\n",
    "\n",
    "_R = DB5[DB5.id.isin( df_[df_.frequency > 450].id )]\n",
    "get_regression(_R)[1].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b07e94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_[df_.frequency > 450].to_csv(path+folder+ \"R_ids_alpha_1.9930.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93bd770",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
