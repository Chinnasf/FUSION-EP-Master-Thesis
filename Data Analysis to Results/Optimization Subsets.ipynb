{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f12b0996",
   "metadata": {},
   "source": [
    "# Frequency in IDs that Decreases $\\alpha_R$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a7055cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from IPython.core.debugger import Pdb #Pdb().set_trace()\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "coeffs = ['IP', 'BT', 'NEL', 'PLTH', 'RGEO', 'KAREA', 'EPS', 'MEFF']\n",
    "path = \"../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b991173",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sampling = pd.read_csv(path + \"decreased_dataset_random_sampling_500_decreasing_points.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06cfd567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After sampling size of 1462, all alpha-R in ramdon sampling will be < 0.6718\n"
     ]
    }
   ],
   "source": [
    "df = random_sampling.describe().T\n",
    "\n",
    "threshold = 0.64\n",
    "min_subset_size = int(df[df['min'] < threshold].index[0].split(\"_\")[-1])\n",
    "\n",
    "amounts = random_sampling.columns[min_subset_size - 1:]\n",
    "max_alpha_R = round((random_sampling[amounts].describe().T)[\"max\"].sort_values().iloc[-2], 4)\n",
    "\n",
    "random_sampling = random_sampling[random_sampling.columns[min_subset_size-1:]]\n",
    "print(f\"After sampling size of {min_subset_size}, all alpha-R in ramdon sampling will be < {max_alpha_R}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10c1f8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB2P8 = pd.read_csv(path+\"DB2P8.csv\")\n",
    "DB5 = pd.read_csv(path+\"DB5.csv\")\n",
    "DB2 = DB2P8[DB5.columns] # Because DB2P8 has more columns than DB5\n",
    "\n",
    "# There is two shots from DB2P8 missing in DB5\n",
    "missing_shots = DB2[~DB2.id.isin( DB5.id.values )].reset_index(drop=True)\n",
    "DB5 = pd.concat([DB5, missing_shots], axis=0, ignore_index=True)\n",
    "\n",
    "decreasing_ds = pd.read_csv(path+\"decreasing_dataset_info.csv\")\n",
    "# Re-Introduce Dataset | What's new in DB5 that decreases Î±R\n",
    "R_dec = DB5[DB5.id.isin(decreasing_ds.id)].reset_index(drop=True) \n",
    "\n",
    "R_dec[\"decreasing_pts\"] = R_dec[\"id\"].map(dict(zip(decreasing_ds.id, decreasing_ds.decreased)))\n",
    "R_dec[\"decreasing_weights\"] = R_dec[\"id\"].map(dict(zip(decreasing_ds.id, decreasing_ds.weights)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f080acaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regression(_R):\n",
    "    \"\"\"\n",
    "    ASSUMING DATA IS ***NOT*** GIVEN IN LOG-SCALE\n",
    "    \"\"\"\n",
    "    data = pd.concat([DB2, _R],\n",
    "                     axis=0, \n",
    "                     ignore_index=True\n",
    "                    )\n",
    "    Y_ = data[[\"TAUTH\"]].apply(np.log).to_numpy()\n",
    "    # Adding a column for the intercept\n",
    "    _df = data[coeffs].apply(np.abs).apply(np.log)\n",
    "    _df.insert(\n",
    "        loc = 0, \n",
    "        column = \"intercept\", \n",
    "        value = np.ones(len(_df))\n",
    "    )\n",
    "    X_ = _df.to_numpy()\n",
    "    n_, p_ = X_.shape\n",
    "    model = sm.OLS(Y_,X_)\n",
    "    regression = model.fit()\n",
    "    return data, regression, (n_,p_)\n",
    "\n",
    "# Getting regression of DB2P8 only. \n",
    "empty_R = R_dec[R_dec.id.isin([0])]\n",
    "regression_DB2= get_regression( empty_R )[1]\n",
    "#regression_DB2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76aa0aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_num_of_sampling = len(random_sampling.columns[:-1])\n",
    "seeds = random_sampling.seed.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9697f4d1",
   "metadata": {},
   "source": [
    "```python\n",
    "for i,s in enumerate(seeds):\n",
    "    for j in range(total_num_of_sampling):\n",
    "        amount = int(random_sampling.columns[j].split(\"_\")[-1])\n",
    "        R_sampled = R_dec.sample(n=amount, weights='decreasing_pts', random_state=s)\n",
    "        # Getting diverse samples for alpha_R below 0.9\n",
    "        alpha_R = get_regression( R_sampled )[1].params[5]\n",
    "        IDs =  R_sampled.id.values\n",
    "        \n",
    "        with open(path+f'IDs/IDs_alpha_({i}_{j})_{alpha_R}.csv', mode='w', newline='') as csv_file:\n",
    "            # create a CSV writer object with the '|' delimiter\n",
    "            writer = csv.writer(csv_file, delimiter='|')\n",
    "            # write the header row\n",
    "            writer.writerow(['ids'])\n",
    "            \n",
    "            for id_ in IDs:\n",
    "                writer.writerow([id_])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a27d559",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "search_strings = decreasing_ds.id.values\n",
    "string_counts = {string: 0 for string in search_strings}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f830afa",
   "metadata": {},
   "source": [
    "```Python\n",
    "# loop through each file in the folder\n",
    "for filename in os.listdir(path+\"IDs\"):\n",
    "    file_path = os.path.join(path+\"IDs\", filename)\n",
    "    # load the CSV file into a pandas DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "    # count the occurrences of each search string in the DataFrame\n",
    "    for string in search_strings:\n",
    "        count = df[df['ids'].str.contains(string, na=False)].shape[0]\n",
    "        string_counts[string] += count\n",
    "        \n",
    "df_ = pd.DataFrame([string_counts.keys(), string_counts.values()]).T.rename(columns={0:\"id\", 1:\"frequency\"})\n",
    "#df_.to_csv(path+\"id_vs_frequency_decreasing_ds.csv\", index=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c2f8f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = pd.read_csv(path + \"id_vs_frequency_decreasing_ds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4db829f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8297, 8302, 8320, 8288, 8251, 8312, 8292, 8305, 8298, 8331, 8290,\n",
       "       8313, 8314, 8285, 8303, 8294, 8296, 8281, 8248, 8304, 8307, 8317,\n",
       "       8283,    0, 8300, 8229, 8255, 8293, 8319, 8316, 8333, 8252, 8301,\n",
       "       8287, 8308, 8310, 8311, 8309, 8321, 8318, 8306, 8275, 8274, 8295,\n",
       "       8338, 8278, 8277, 8291, 8323, 8286, 8299, 8284, 8289, 8280, 8328,\n",
       "       8262, 8282, 8315, 8268, 8276, 8279, 8324, 8272, 8267, 8271, 8327,\n",
       "       8326, 8265, 8322, 8266, 8332, 8330, 8329, 8256, 8264, 8260, 8325,\n",
       "       8258])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_[df_.frequency < 9000][\"frequency\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9f14557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AEWB71</td>\n",
       "      <td>8297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UAAXGA</td>\n",
       "      <td>8302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53LSPJ</td>\n",
       "      <td>8320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FLO8WI</td>\n",
       "      <td>8320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TKCDLW</td>\n",
       "      <td>8297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2533</th>\n",
       "      <td>G8OILS</td>\n",
       "      <td>8312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2537</th>\n",
       "      <td>ST5FL8</td>\n",
       "      <td>8317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2538</th>\n",
       "      <td>G8PHEQ</td>\n",
       "      <td>8300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2539</th>\n",
       "      <td>K3O76W</td>\n",
       "      <td>8279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2540</th>\n",
       "      <td>ZD6MZS</td>\n",
       "      <td>8294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1486 rows Ã 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  frequency\n",
       "0     AEWB71       8297\n",
       "1     UAAXGA       8302\n",
       "2     53LSPJ       8320\n",
       "3     FLO8WI       8320\n",
       "4     TKCDLW       8297\n",
       "...      ...        ...\n",
       "2533  G8OILS       8312\n",
       "2537  ST5FL8       8317\n",
       "2538  G8PHEQ       8300\n",
       "2539  K3O76W       8279\n",
       "2540  ZD6MZS       8294\n",
       "\n",
       "[1486 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_[df_.frequency > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1007fad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8338"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(df_[\"frequency\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d5c8580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8229"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(df_[df_.frequency > 0][\"frequency\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac52939b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
