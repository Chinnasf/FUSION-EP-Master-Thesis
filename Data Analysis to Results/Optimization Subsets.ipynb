{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f12b0996",
   "metadata": {},
   "source": [
    "# Frequency in IDs that Decreases $\\alpha_R$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a7055cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from IPython.core.debugger import Pdb #Pdb().set_trace()\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "coeffs = ['IP', 'BT', 'NEL', 'PLTH', 'RGEO', 'KAREA', 'EPS', 'MEFF']\n",
    "path = \"../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b991173",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sampling = pd.read_csv(path + \"decreased_dataset_random_sampling_500_decreasing_points.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06cfd567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After sampling size of 1061, all alpha-R in ramdon sampling will be < 0.8631\n"
     ]
    }
   ],
   "source": [
    "df = random_sampling.describe().T\n",
    "\n",
    "threshold = 0.75\n",
    "min_subset_size = int(df[df['min'] < threshold].index[0].split(\"_\")[-1])\n",
    "\n",
    "amounts = random_sampling.columns[min_subset_size - 1:]\n",
    "max_alpha_R = round((random_sampling[amounts].describe().T)[\"max\"].sort_values().iloc[-2], 4)\n",
    "\n",
    "random_sampling = random_sampling[random_sampling.columns[min_subset_size-1:]]\n",
    "print(f\"After sampling size of {min_subset_size}, all alpha-R in ramdon sampling will be < {max_alpha_R}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10c1f8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB2P8 = pd.read_csv(path+\"DB2P8.csv\")\n",
    "DB5 = pd.read_csv(path+\"DB5.csv\")\n",
    "DB2 = DB2P8[DB5.columns] # Because DB2P8 has more columns than DB5\n",
    "\n",
    "# There is two shots from DB2P8 missing in DB5\n",
    "missing_shots = DB2[~DB2.id.isin( DB5.id.values )].reset_index(drop=True)\n",
    "DB5 = pd.concat([DB5, missing_shots], axis=0, ignore_index=True)\n",
    "\n",
    "decreasing_ds = pd.read_csv(path+\"decreasing_dataset_info.csv\")\n",
    "# Re-Introduce Dataset | What's new in DB5 that decreases Î±R\n",
    "R_dec = DB5[DB5.id.isin(decreasing_ds.id)].reset_index(drop=True) \n",
    "\n",
    "R_dec[\"decreasing_pts\"] = R_dec[\"id\"].map(dict(zip(decreasing_ds.id, decreasing_ds.decreased)))\n",
    "R_dec[\"decreasing_weights\"] = R_dec[\"id\"].map(dict(zip(decreasing_ds.id, decreasing_ds.weights)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f080acaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regression(_R):\n",
    "    \"\"\"\n",
    "    ASSUMING DATA IS ***NOT*** GIVEN IN LOG-SCALE\n",
    "    \"\"\"\n",
    "    data = pd.concat([DB2, _R],\n",
    "                     axis=0, \n",
    "                     ignore_index=True\n",
    "                    )\n",
    "    Y_ = data[[\"TAUTH\"]].apply(np.log).to_numpy()\n",
    "    # Adding a column for the intercept\n",
    "    _df = data[coeffs].apply(np.abs).apply(np.log)\n",
    "    _df.insert(\n",
    "        loc = 0, \n",
    "        column = \"intercept\", \n",
    "        value = np.ones(len(_df))\n",
    "    )\n",
    "    X_ = _df.to_numpy()\n",
    "    n_, p_ = X_.shape\n",
    "    model = sm.OLS(Y_,X_)\n",
    "    regression = model.fit()\n",
    "    return data, regression, (n_,p_)\n",
    "\n",
    "# Getting regression of DB2P8 only. \n",
    "empty_R = R_dec[R_dec.id.isin([0])]\n",
    "regression_DB2= get_regression( empty_R )[1]\n",
    "#regression_DB2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76aa0aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_num_of_sampling = len(random_sampling.columns[:-1])\n",
    "seeds = random_sampling.seed.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1c54290",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,s in enumerate(seeds):\n",
    "    for j in range(total_num_of_sampling):\n",
    "        amount = int(random_sampling.columns[j].split(\"_\")[-1])\n",
    "        R_sampled = R_dec.sample(n=amount, weights='decreasing_pts', random_state=s)\n",
    "        # Getting diverse samples for alpha_R below 0.9\n",
    "        alpha_R = get_regression( R_sampled )[1].params[5]\n",
    "        IDs = get_regression( R_sampled )[0].id.values \n",
    "        \n",
    "        with open(path+f'IDs/IDs_alpha_({i+j})_{alpha_R}.csv', mode='w', newline='') as csv_file:\n",
    "            # create a CSV writer object with the '|' delimiter\n",
    "            writer = csv.writer(csv_file, delimiter='|')\n",
    "            # write the header row\n",
    "            writer.writerow(['ids'])\n",
    "            \n",
    "            for id_ in IDs:\n",
    "                writer.writerow([id_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a27d559",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad6bf4ac",
   "metadata": {},
   "source": [
    "```python\n",
    "# open a CSV file for writing\n",
    "with open(path+'alphas_with_ids.csv', mode='w', newline='') as csv_file:\n",
    "    # create a CSV writer object with the '|' delimiter\n",
    "    writer = csv.writer(csv_file, delimiter='|')\n",
    "    # write the header row\n",
    "    writer.writerow(['alpha', 'ids'])\n",
    "    for i,s in enumerate(seeds):\n",
    "        for j in range(total_num_of_sampling):\n",
    "            amount = int(random_sampling.columns[j].split(\"_\")[-1])\n",
    "            R_sampled = R_dec.sample(n=amount, weights='decreasing_pts', random_state=s)\n",
    "            # Getting diverse samples for alpha_R below 0.9\n",
    "            ALPHAs = get_regression( R_sampled )[1].params[5] \n",
    "            IDs = get_regression( R_sampled )[0].id.values \n",
    "            # Storing results in CSV file\n",
    "            writer.writerow([ALPHAs, IDs])\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22dc04e",
   "metadata": {},
   "source": [
    "Diosito ya por favor :((((((((((((((\n",
    "\n",
    "```python\n",
    "df = pd.read_csv(path+\"alphas_with_ids.csv\", delimiter=\"|\")\n",
    "df.ids = df.ids.str.replace(\"(\\[)|(\\])|(\\')\",\"\",regex=True).str.replace(\"\\s\",\",\",regex=True)\n",
    "df.ids = df.ids.apply(lambda x: x.split(\",\"))\n",
    "\n",
    "list_ids = [0]\n",
    "for l in df.ids:\n",
    "    list_ids += l\n",
    "list_ids = list_ids[1:]\n",
    "                                        \n",
    "labels, values = zip(*Counter(list_ids).items())\n",
    "indexes = np.arange(len(labels))\n",
    "width = 1\n",
    "\n",
    "plt.bar(indexes, values, width)\n",
    "plt.xticks(indexes + width * 0.5, labels)\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1f8cd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
