{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f46c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330169e7",
   "metadata": {},
   "source": [
    "# TUNED | RANDOM FOREST | LOW MULTICOLLINEARITY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce03add2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "import tokamakTK\n",
    "\n",
    "import pydotplus\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve, precision_recall_fscore_support\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "path = \"../../data/\"\n",
    "fig_path = \"../../../../LATEX/Latex Images/\"\n",
    "plt.rc('font',family = 'serif')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b4cc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtained from Optimization\n",
    "\n",
    "min_subset_ids = pd.read_csv(path+\"R_ids_alpha_0.6357.csv\")\n",
    "\n",
    "DB2 = pd.read_csv(path+\"DB2P8.csv\")\n",
    "DB5 = pd.read_csv(path+\"SELDB5_SVD.csv\", low_memory=False) \n",
    "\n",
    "# Setting ELMy Dataset\n",
    "DB5 = DB5[DB5[\"PHASE\"].isin(['HGELM', 'HSELM', 'HGELMH', 'HSELMH'])]\n",
    "\n",
    "# REMOVING SPHERICAL TOKAMAKS\n",
    "#DB5 = DB5[~DB5.TOK.isin(['MAST', 'NSTX', 'START'])]\n",
    "\n",
    "\n",
    "# There is two shots from DB2P8 missing in DB5\n",
    "missing_shots = DB2[~DB2.id.isin( DB5.id.values )].reset_index(drop=True)\n",
    "DB5 = pd.concat([DB5, missing_shots], axis=0, ignore_index=True)\n",
    "\n",
    "# Labeling shots that had great impact in decreasing alpha_R\n",
    "DB5.insert(loc=2,column=\"label\",value=[0]*len(DB5))\n",
    "DB5.loc[(DB5[DB5.id.isin(min_subset_ids.id)].index), \"label\"] = 1\n",
    "\n",
    "\n",
    "print(\n",
    "    f\"{ round( (len(min_subset_ids)/len(DB5))*100     ,2)  }% of the data decreased alpha_R\\n\" + \n",
    "    f\"{ round( (1 - len(min_subset_ids)/len(DB5))*100 ,2)  }% of the data did not decrease alpha_R\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e2e5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['AUXHEAT', 'BEIMHD', 'BETASTAR', 'BT', 'CONFIG', 'DIVMAT', 'DWDIA', 'ECHMODE', \n",
    "            'ELMFREQ', 'ELMTYPE', 'EVAP', 'ICSCHEME', 'IP', \n",
    "            'LIMMAT', 'NEL', 'NESOL', 'NUSTAR', 'PECRH', 'PELLET', 'PFLOSS', \n",
    "            'PICRH', 'POHM', 'PRAD', 'PREMAG', 'Q95', 'RHOSTAR', \n",
    "            'TIV', 'TOK', 'TORQ', 'WALMAT', 'WFFORM', 'WFICFORM', 'ZEFF', 'ZEFFNEO']\n",
    "\"\"\"\n",
    "(array([0.86479592, 0.9319407 ]),\n",
    " array([0.77045455, 0.96309192]),\n",
    " array([0.81490385, 0.94726027]),\n",
    " array([ 440, 1436]))\n",
    "\"\"\"\n",
    "\"\"\"# --------------------------------------------------------------------------------------------\n",
    "# Most important features\n",
    "features = ['NUSTAR', 'RHOSTAR', 'Q95', 'WFFORM', 'BETASTAR']\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "(array([0.80705882, 0.93314955]),\n",
    " array([0.77954545, 0.94289694]),\n",
    " array([0.79306358, 0.93799792]),\n",
    " array([ 440, 1436]))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0270fd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB5 = tokamakTK.clean_categorical_data(DB5)\n",
    "\n",
    "# Needed to respectively clean each dtype\n",
    "num_features = DB5[features].select_dtypes(include=['int', 'float']).columns.tolist()\n",
    "cat_features = DB5[features].select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "data_num = DB5[num_features+[\"TOK\",\"DATE\"]]\n",
    "data_cat = DB5[cat_features]\n",
    "\n",
    "# Notice that for trees, it is not necessary to scale the features, but can improve the performance\n",
    "\"\"\"\n",
    "    It's a good practice to consider feature scaling as part of the overall data \n",
    "    preprocessing pipeline, especially if there are specific considerations \n",
    "    or requirements in your analysis.\n",
    "\"\"\"\n",
    "data_num = tokamakTK.clean_numerical_data(data_num, SS_scaling=False, UL_scale=True)\n",
    "\n",
    "data_ = pd.concat([data_num,\n",
    "                  (pd.concat([\n",
    "                       DB5[[\"label\"]], \n",
    "                       tokamakTK.encode_categorical_ohe(data_cat)\n",
    "                      ], axis=1)\n",
    "                  )],\n",
    "                  axis=1\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33726fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_.drop(\"label\", axis=1)\n",
    "y = data_[\"label\"]\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=71, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55828e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(min_samples_split=2,  \n",
    "                            min_samples_leaf=1,\n",
    "                            min_impurity_decrease=0.0007,\n",
    "                            n_estimators = 90,\n",
    "                            max_depth = 23,\n",
    "                            criterion='entropy',\n",
    "                            max_features=None,\n",
    "                            n_jobs=-1,\n",
    "                            random_state=71\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f138291",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train, y_train)\n",
    "y_pred= rf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5918ba4b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,4))\n",
    "\n",
    "# keep probabilities for the positive outcome only\n",
    "y_pred = y_pred[:, 1]\n",
    "# calculate pr-curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_pred)\n",
    "# plot the roc curve for the model\n",
    "no_skill = len(y_test[y_test==1]) / len(y_test)\n",
    "plt.plot(recall, precision, marker='.', label='Random Forest', color=\"r\")\n",
    "plt.plot([0,1], [no_skill,no_skill], linestyle='--', label='No Skill', color=\"k\")\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title(\"Low Multicollinearity Variables\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf286eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ = rf.predict(X_test)\n",
    "precision_recall_fscore_support(y_test, y_pred_, labels=[1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cc9b63",
   "metadata": {},
   "source": [
    "## PERMUTATION IMPORTANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661037ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_permutations = 200\n",
    "scoring_metrics = [\"precision\", \"recall\"]\n",
    "permutations = permutation_importance(rf, X_test, y_test, n_repeats=n_permutations, \n",
    "                                     scoring=scoring_metrics,\n",
    "                                     random_state=71)\n",
    "Precision, Recall = [pd.DataFrame(np.zeros((len(X.columns), 2)), \n",
    "                                  index=X.columns, columns=[\"mean\", \"std\"])]*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a228bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in permutations[\"precision\"].importances_mean.argsort()[::-1]:\n",
    "    if permutations[\"precision\"].importances_mean[i] - 2 * permutations[\"precision\"].importances_std[i] > 0:\n",
    "        Precision.loc[X.columns[i], \"mean\"] = np.round(permutations[\"precision\"].importances_mean[i],4)\n",
    "        Precision.loc[X.columns[i], \"std\"] = np.round(permutations[\"precision\"].importances_std[i],4)\n",
    "Precision.sort_values(\"mean\", ascending=False, inplace=True)\n",
    "\n",
    "for i in permutations[\"recall\"].importances_mean.argsort()[::-1]:\n",
    "    if permutations[\"recall\"].importances_mean[i] - 2 * permutations[\"recall\"].importances_std[i] > 0:\n",
    "        Recall.loc[X.columns[i], \"mean\"] = np.round(permutations[\"recall\"].importances_mean[i],4)\n",
    "        Recall.loc[X.columns[i], \"std\"] = np.round(permutations[\"recall\"].importances_std[i],4)\n",
    "Precision.sort_values(\"mean\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d484deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have two dataframes: Precision and Recall\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))  # Create a figure with two subplots\n",
    "\n",
    "# First subplot: Precision\n",
    "axes[0].bar(Precision.index[:amount], Precision['mean'][:amount], color=\"#A84547\")\n",
    "axes[0].errorbar(Precision.index[:amount], Precision['mean'][:amount], yerr=Precision['std'][:amount], \n",
    "                 fmt='.', capsize=4, color='k')\n",
    "for x, y, err in zip(range(amount), Precision['mean'][:amount], Precision['std'][:amount]):\n",
    "    axes[0].annotate(f'±{err:.2f}', xy=(x, y + err), xytext=(0, 4), textcoords='offset points',\n",
    "                     ha='center', va='bottom', color='k')\n",
    "axes[0].set_ylabel('Mean Value', fontsize=15)\n",
    "axes[0].set_title('Precision', fontsize=17)\n",
    "axes[0].set_xticks(Precision.index[:amount])\n",
    "axes[0].set_xticklabels(Precision.index[:amount], rotation=45)\n",
    "axes[0].spines['top'].set_visible(False)\n",
    "axes[0].spines['right'].set_visible(False)\n",
    "\n",
    "# Second subplot: Recall\n",
    "axes[1].bar(Recall.index[:amount], Recall['mean'][:amount], color=\"#A84547\")\n",
    "axes[1].errorbar(Recall.index[:amount], Recall['mean'][:amount], yerr=Recall['std'][:amount], \n",
    "                 fmt='.', capsize=4, color='k')\n",
    "for x, y, err in zip(range(amount), Recall['mean'][:amount], Recall['std'][:amount]):\n",
    "    axes[1].annotate(f'±{err:.2f}', xy=(x, y + err), xytext=(0, 4), textcoords='offset points',\n",
    "                     ha='center', va='bottom', color='k')\n",
    "#axes[1].set_ylabel('Mean Value')\n",
    "axes[1].set_title('Recall', fontsize=17)\n",
    "axes[1].set_xticks(Recall.index[:amount])\n",
    "axes[1].set_xticklabels(Recall.index[:amount], rotation=45)\n",
    "axes[1].spines['top'].set_visible(False)\n",
    "axes[1].spines['right'].set_visible(False)\n",
    "\n",
    "axes[0].tick_params(axis='both', which='major', labelsize=12, width=2)\n",
    "axes[0].tick_params(axis='both', which='minor', labelsize=10, width=1)\n",
    "axes[1].tick_params(axis='both', which='major', labelsize=12, width=2)\n",
    "axes[1].tick_params(axis='both', which='minor', labelsize=10, width=1)\n",
    "\n",
    "plt.tight_layout()  # Adjust spacing between subplots\n",
    "plt.show()  # Display the figure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84876eae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
