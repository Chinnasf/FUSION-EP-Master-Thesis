{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f691e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b471bc",
   "metadata": {},
   "source": [
    "# TUNED | RANDOM FOREST | LOW MULTICOLLINEARITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f834bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "import tokamakTK\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve, precision_recall_fscore_support\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "path = \"../../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b09db631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtained from Optimization\n",
    "\n",
    "min_subset_ids = pd.read_csv(path+\"R_ids_alpha_0.6357.csv\")\n",
    "\n",
    "DB2 = pd.read_csv(path+\"DB2P8.csv\")\n",
    "DB5 = pd.read_csv(path+\"SELDB5_SVD.csv\", low_memory=False) \n",
    "\n",
    "# Setting ELMy Dataset\n",
    "DB5 = DB5[DB5[\"PHASE\"].isin(['HGELM', 'HSELM', 'HGELMH', 'HSELMH'])]\n",
    "\n",
    "# REMOVING SPHERICAL TOKAMAKS\n",
    "DB5 = DB5[~DB5.TOK.isin(['MAST', 'NSTX', 'START'])]\n",
    "\n",
    "\n",
    "# There is two shots from DB2P8 missing in DB5\n",
    "missing_shots = DB2[~DB2.id.isin( DB5.id.values )].reset_index(drop=True)\n",
    "DB5 = pd.concat([DB5, missing_shots], axis=0, ignore_index=True)\n",
    "\n",
    "# Labeling shots that had great impact in decreasing alpha_R\n",
    "DB5.insert(loc=2,column=\"label\",value=[0]*len(DB5))\n",
    "DB5.loc[(DB5[DB5.id.isin(min_subset_ids.id)].index), \"label\"] = 1\n",
    "\n",
    "\n",
    "print(\n",
    "    f\"{ round( (len(min_subset_ids)/len(DB5))*100     ,2)  }% of the data decreased alpha_R\\n\" + \n",
    "    f\"{ round( (1 - len(min_subset_ids)/len(DB5))*100 ,2)  }% of the data did not decrease alpha_R\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adc6e00",
   "metadata": {},
   "source": [
    "Class distribution can be considered is skewed.\n",
    "\n",
    "## Treatment to Categorical and Numerical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "820873ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['AUXHEAT','BEIMHD','BETASTAR','BT','CONFIG','DIVMAT','DIVNAME','DWDIA',\n",
    "            'ECHMODE','ELMFREQ','ELMTYPE','ENBI','EPS','EVAP','HYBRID','ICSCHEME','IP',\n",
    "            'KAREA','LHTIME','LIMMAT','MEFF','NEL','NESOL','NUSTAR','OMEGACYCL',\n",
    "            'PECRH','PELLET','PFLOSS','PICRH','PNBI','POHM','PRAD','PREMAG','QCYL5',\n",
    "            'RHOSTAR','TAV','TIV','TOK','TORQ','WALMAT','WFFORM','WFICFORM',\n",
    "            'ZEFF','ZEFFNEO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd2d96e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB5 = tokamakTK.clean_categorical_data(DB5)\n",
    "\n",
    "\n",
    "# Needed to respectively clean each dtype\n",
    "num_features = DB5[features].select_dtypes(include=['int', 'float']).columns.tolist()\n",
    "cat_features = DB5[features].select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "\n",
    "data_num = DB5[num_features+[\"TOK\",\"DATE\"]]\n",
    "data_cat = DB5[cat_features]\n",
    "\n",
    "data_num = tokamakTK.clean_numerical_data(data_num)\n",
    "\n",
    "data_ = pd.concat([data_num,\n",
    "                  (pd.concat([\n",
    "                       DB5[[\"label\"]], \n",
    "                       tokamakTK.encode_categorical_ohe(data_cat)\n",
    "                      ], axis=1)\n",
    "                  )],\n",
    "                  axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b7052ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_.drop(\"label\", axis=1)\n",
    "y = data_[\"label\"]\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=71, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46467d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define random forest classifier with preprocessor as a pipeline\n",
    "\n",
    "rf = RandomForestClassifier(min_samples_split=2,\n",
    "                            min_samples_leaf=1,\n",
    "                            n_estimators = 290,\n",
    "                            max_depth = 22,\n",
    "                            criterion='entropy',\n",
    "                            max_features=None,\n",
    "                            random_state=71\n",
    "                           )\n",
    "\n",
    "\"\"\"\n",
    "rf = RandomForestClassifier(min_samples_split=2,\n",
    "                            min_samples_leaf=1,\n",
    "                            n_estimators = 290,\n",
    "                            max_depth = 22,\n",
    "                            criterion='entropy',\n",
    "                            max_features=None,\n",
    "                            random_state=71\n",
    "                           )\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred= rf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f793027",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,4))\n",
    "\n",
    "# keep probabilities for the positive outcome only\n",
    "y_pred = y_pred[:, 1]\n",
    "# calculate pr-curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_pred)\n",
    "# plot the roc curve for the model\n",
    "no_skill = len(y_test[y_test==1]) / len(y_test)\n",
    "plt.plot(recall, precision, marker='.', label='Random Forest', color=\"r\")\n",
    "plt.plot([0,1], [no_skill,no_skill], linestyle='--', label='No Skill', color=\"k\")\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title(\"Low Multicollinearity Variables\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0aa30d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_ = rf.predict(X_test)\n",
    "precision_recall_fscore_support(y_test, y_pred_, labels=[1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ada672",
   "metadata": {},
   "source": [
    "## [Feature Importance Based on Mean Decrease in Impurity](https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html)\n",
    "\n",
    "Feature importances are provided by the fitted attribute `feature_importances_` and they are computed as the mean and standard deviation of accumulation of the impurity decrease within each tree.\n",
    "\n",
    "**WARNING**:  Impurity-based feature importances can be misleading for high cardinality features (many unique values). See Permutation feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e18a6b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf.feature_importances_\n",
    "\n",
    "feature_importances = pd.DataFrame({\"feature\": X.columns, \"importance\": importances})\n",
    "feature_importances = feature_importances.sort_values(\"importance\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "df = pd.DataFrame(feature_importances)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9bc36f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(11,4))\n",
    "plt.bar(df[df.importance > 0.5e-2].feature, df[df.importance > 0.5e-2].importance, color=\"gray\")\n",
    "plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48d0de89",
   "metadata": {},
   "outputs": [],
   "source": [
    "___________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adda254",
   "metadata": {},
   "source": [
    "# Permutation Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e0dbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_permutations = 100\n",
    "feature_importance = np.zeros(X_train.shape[1])\n",
    "\n",
    "recall = precision_recall_fscore_support(y_test, y_pred_, labels=[1,0])[1][0]\n",
    "\n",
    "for i in range(X_train.shape[1]):\n",
    "    recall_diffs = np.zeros(n_permutations)\n",
    "    for j in range(n_permutations):\n",
    "        X_test_permuted = X_test.copy()\n",
    "        X_test_permuted.iloc[:, i] = np.random.permutation(X_test.iloc[:, i])\n",
    "        y_pred_permuted = rf.predict(X_test_permuted)\n",
    "        recall_permuted = precision_recall_fscore_support(y_test, y_pred_permuted, labels=[1,0])[1][0]\n",
    "        recall_diffs[j] = recall_permuted - recall\n",
    "    feature_importance[i] = np.mean(recall_diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0db6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_idx = np.argsort(abs(feature_importance))[::-1][:30]\n",
    "plt.bar(range(len(sorted_idx)), abs(feature_importance[sorted_idx]))\n",
    "plt.xticks(range(len(sorted_idx)), X_train.columns[sorted_idx], rotation=90)\n",
    "plt.ylabel('Feature importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5867df",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_idx = np.argsort(abs(feature_importance))[::-1][:15]\n",
    "plt.bar(range(len(sorted_idx)), abs(feature_importance[sorted_idx]))\n",
    "plt.xticks(range(len(sorted_idx)), X_train.columns[sorted_idx], rotation=90)\n",
    "plt.ylabel('Feature importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aace390e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns[sorted_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03b815b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
