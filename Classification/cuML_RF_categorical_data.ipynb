{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f691e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4786c09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f834bdc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cudf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msm\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpatches\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpatches\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcudf\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcuml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcuml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split, GridSearchCV, StratifiedKFold\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cudf'"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "\n",
    "import cudf\n",
    "\n",
    "\n",
    "from cuml.ensemble import RandomForestClassifier\n",
    "from cuml.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import precision_recall_curve, precision_recall_fscore_support\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "path = \"../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93c9d30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: conda: command not found\r\n"
     ]
    }
   ],
   "source": [
    "! conda list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b09db631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.69% of the data decreased alpha_R\n",
      "59.31% of the data did not decrease alpha_R\n"
     ]
    }
   ],
   "source": [
    "# Obtained from Optimization\n",
    "\n",
    "min_subset_ids = pd.read_csv(path+\"id_vs_frequency_decreasing_ds.csv\")\n",
    "#min_subset_ids = pd.read_csv(path+\"R_ids_alpha_0.6357.csv\")\n",
    "\n",
    "DB2 = pd.read_csv(path+\"DB2P8.csv\")\n",
    "DB5 = pd.read_csv(path+\"SELDB5_SVD.csv\", low_memory=False) \n",
    "DB5 = DB5[DB5[\"PHASE\"].isin(['HGELM', 'HSELM', 'HGELMH', 'HSELMH'])]\n",
    "\n",
    "# There is two shots from DB2P8 missing in DB5\n",
    "missing_shots = DB2[~DB2.id.isin( DB5.id.values )].reset_index(drop=True)\n",
    "DB5 = pd.concat([DB5, missing_shots], axis=0, ignore_index=True)\n",
    "\n",
    "# Labeling shots that had great impact in decreasing alpha_R\n",
    "DB5.insert(loc=2,column=\"label\",value=[0]*len(DB5))\n",
    "DB5.loc[(DB5[DB5.id.isin(min_subset_ids.id)].index), \"label\"] = 1\n",
    "\n",
    "print(\n",
    "    f\"{ round( (len(min_subset_ids)/len(DB5))*100     ,2)  }% of the data decreased alpha_R\\n\" + \n",
    "    f\"{ round( (1 - len(min_subset_ids)/len(DB5))*100 ,2)  }% of the data did not decrease alpha_R\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adc6e00",
   "metadata": {},
   "source": [
    "Class distribution can be considered is skewed.\n",
    "\n",
    "## Treatment to Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd2d96e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "research_features = ['NEL','TAV','BT','RHOSTAR','NUSTAR','BETASTAR']\n",
    "\n",
    "TOK_characteristics = [\"DIVNAME\",\"WALMAT\",\"DIVMAT\",\"LIMMAT\"]\n",
    "categorical = [\"PREMAG\",\"HYBRID\",\"CONFIG\",\"ELMTYPE\",\n",
    "               \"ICSCHEME\",\"AUXHEAT\",\"EVAP\"] + TOK_characteristics \n",
    "\n",
    "DB5[categorical] = DB5[categorical].fillna('UNKNOWN')\n",
    "DB5[\"DIVNAME\"]   = DB5[\"DIVNAME\"].str.replace(\"NONAME\",\"UNKNOWN\",regex=False)\n",
    "\n",
    "DB5[\"DIVMAT\"] = DB5[\"DIVMAT\"].str.replace(\"CC\",\"C\",regex=False)\n",
    "DB5[\"DIVMAT\"] = DB5[\"DIVMAT\"].str.replace(\"TI1\",\"TI12\",regex=False)\n",
    "DB5[\"DIVMAT\"] = DB5[\"DIVMAT\"].str.replace(\"TI2\",\"TI12\",regex=False)\n",
    "\n",
    "DB5[\"DIVNAME\"] = DB5[\"DIVNAME\"].str.replace(\"(DIV-I)|(DV-IPRE)|(DV-IPOST)\",\n",
    "                                            \"DV-I\",regex=True)\n",
    "DB5[\"DIVNAME\"] = DB5[\"DIVNAME\"].str.replace(\"(DIV-II)|(DV-IIc)|(DV-II-C)|(DV-IIb)|(DV-IIc)|(DV-IId)|(DV-IId)\",\n",
    "                                            \"DV-II\",regex=True)\n",
    "DB5[\"DIVNAME\"] = DB5[\"DIVNAME\"].str.replace(\"(MARK0)|(MARKI)|(MARKIIA)|(MARKGB)|(MARKGBSR)|\"+\n",
    "                                            \"(MARKIA)|(MARKIAP)|(MARKSR)|(MARKA)|(MARKP)\",\n",
    "                                            \"MARK\",regex=True)\n",
    "\n",
    "DB5[\"ICSCHEME\"]   = DB5[\"ICSCHEME\"].str.replace(\"OFF\",\"NONE\",regex=False)\n",
    "\n",
    "# Removing noise on heating scheme | the removed coluns are shots from 1996\n",
    "DB5 = DB5[~DB5[\"AUXHEAT\"].isin([\"UNKNOWN\"])]\n",
    "\n",
    "DB5[\"EVAP\"] = DB5[\"EVAP\"].str.replace(\"CARBH\",\"C-H\",regex=True)\n",
    "DB5[\"EVAP\"] = DB5[\"EVAP\"].str.replace(\"CARB\",\"C\",regex=True)\n",
    "DB5[\"EVAP\"] = DB5[\"EVAP\"].str.replace(\"BOROC\",\"C-BO\",regex=True)\n",
    "DB5[\"EVAP\"] = DB5[\"EVAP\"].str.replace(\"(BOROA)|(BOROB)|(BOROX)|(BOR)\",\"BO\",regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8d7aec",
   "metadata": {},
   "source": [
    "## Treatment to Numerical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5b5dd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "plasma_characteristics = [\"QCYL5\",\"BEIMHD\",\"PREMAG\",\"LHTIME\",\"HYBRID\",\n",
    "                          \"CONFIG\",\"DWDIA\",\"WMHD\",\"TORQ\"\n",
    "                         ] \n",
    "TOK_characteristics = [\"TOK\",\"DIVNAME\",\"WALMAT\",\"DIVMAT\",\"LIMMAT\"]\n",
    "ELM = [\"ELMTYPE\",\"ELMFREQ\"]\n",
    "heating = [\"PECRH\", \"PICRH\", \"ICSCHEME\",\"AUXHEAT\"]\n",
    "impurities = [\"EVAP\",\"ZEFF\",\"ZEFFNEO\",\"PRAD\",\"POHM\",\"ENBI\"]\n",
    " # corrections on power loss | NBI Power lost by unconfined orbits\n",
    "power = [\"PLTH\",\"PFLOSS\"]\n",
    "temperatures = [\"TAV\",\"TEV\",\"TIV\"]\n",
    "# e-density in SOL | total due to NBI| total due to ICRH\n",
    "fast_particles = [\"NESOL\",\"WFFORM\",\"WFICFORM\"] \n",
    "research_features = ['NEL','TAV','BT','RHOSTAR','NUSTAR','BETASTAR']\n",
    "\n",
    "interesting_features = set(plasma_characteristics + TOK_characteristics + ELM + heating + \\\n",
    "                       impurities + power  + fast_particles)\n",
    "\n",
    "data_ = DB5.copy()\n",
    "data_ = data_[list(interesting_features)]\n",
    "\n",
    "num_features = data_.select_dtypes(include=['int', 'float']).columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3044ccd",
   "metadata": {},
   "source": [
    "This is what I had before to join comlumns.\n",
    "\n",
    "```Python\n",
    "DB5_ = pd.DataFrame(StandardScaler().fit_transform( DB5[num_features] ), columns = num_features)\n",
    "data = pd.concat([DB5_,DB5[categorical]], axis=1, join=\"inner\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb6664e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DB5.copy()\n",
    "data = data[num_features + categorical + [\"label\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccdfae7",
   "metadata": {},
   "source": [
    "### Implementation of RF\n",
    "\n",
    "[`sklearn.impute.SimpleImputer`](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html)\n",
    "\n",
    "Univariate imputer for completing missing values with simple strategies. Replace missing values using a descriptive statistic (e.g. mean, median, or most frequent) along each column, or using a constant value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033329be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75145996",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369a59dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b7052ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cudf.from_pandas(data.drop(\"label\", axis=1))\n",
    "y = cudf.from_pandas(data[\"label\"])\n",
    "\n",
    "# Identify categorical and numerical features\n",
    "cat_features = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "num_features = X.select_dtypes(include=[\"int\", \"float\"]).columns.tolist()\n",
    "\n",
    "# Define preprocessing steps for categorical and numerical features\n",
    "cat_preprocessor = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"UNKNOWN\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "num_preprocessor = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy='median')),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "# Combine preprocessing steps for all features using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('cat', cat_preprocessor, cat_features),\n",
    "    ('num', num_preprocessor, num_features)\n",
    "])\n",
    "\n",
    "# split data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=71, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5abc5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from cuml.ensemble import RandomForestClassifier\n",
    "#from cuml.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46467d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define random forest classifier with preprocessor as a pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", RandomForestClassifier(random_state=71))\n",
    "])\n",
    "\n",
    "# Define the hyperparameter grid to search\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [10, 50, 100, 200],  # Number of decision trees in the forest\n",
    "    'classifier__max_depth': [None, 10, 20, 30],     # Max depth of each decision tree\n",
    "    'classifier__min_samples_split': [2, 5, 10],     # Min num. of samples required to split an internal node\n",
    "    'classifier__min_samples_leaf': [1, 2, 4],       # Min num. of samples required to be at a leaf node\n",
    "    'classifier__max_features': ['sqrt', 'log2', None],  # Number of features to consider for the best split\n",
    "    'classifier__criterion': ['gini', 'entropy']     # Function to measure the quality of a split\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV object with stratified sampling\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline, \n",
    "    param_grid, \n",
    "    cv=StratifiedKFold(n_splits=10, shuffle=True, random_state=71),\n",
    "    scoring='recall'\n",
    ")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Get the best hyperparameter values\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "\n",
    "# Train a random forest model with the best hyperparameter values on the entire training set\n",
    "moedel = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(**best_params))\n",
    "])\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Hyperparameters: \", best_params)\n",
    "\n",
    "y_pred = best_pipeline.predict_proba(X_val)\n",
    "\n",
    "# 22:27 to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f793027",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,4))\n",
    "\n",
    "# keep probabilities for the positive outcome only\n",
    "y_pred = y_pred[:, 1]\n",
    "# calculate pr-curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_val, y_pred)\n",
    "# plot the roc curve for the model\n",
    "no_skill = len(y_val[y_val==1]) / len(y_val)\n",
    "plt.plot(recall, precision, marker='.', label='Default Random Forest', color=\"r\")\n",
    "plt.plot([0,1], [no_skill,no_skill], linestyle='--', label='No Skill', color=\"k\")\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title(\"Research Variables\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0aa30d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ = model.predict(X_val)\n",
    "precision_recall_fscore_support(y_val, y_pred_, labels=[1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ada672",
   "metadata": {},
   "source": [
    "## [Feature Importance Based on Mean Decrease in Impurity](https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html)\n",
    "\n",
    "Feature importances are provided by the fitted attribute `feature_importances_` and they are computed as the mean and standard deviation of accumulation of the impurity decrease within each tree.\n",
    "\n",
    "**WARNING**:  Impurity-based feature importances can be misleading for high cardinality features (many unique values). See Permutation feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18a6b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances from trained RF classifier\n",
    "importances = model.named_steps[\"classifier\"].feature_importances_\n",
    "\n",
    "# Get feature names from column transformer\n",
    "cat_encoder = model.named_steps[\"preprocessor\"].named_transformers_[\"cat\"].named_steps[\"onehot\"]\n",
    "feature_names = cat_encoder.get_feature_names_out(cat_features).tolist() + num_features\n",
    "\n",
    "# Create a pandas dataframe to display feature importances\n",
    "feature_importances = pd.DataFrame({\"feature\": feature_names, \"importance\": importances})\n",
    "feature_importances = feature_importances.sort_values(\"importance\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c991b672",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(feature_importances)\n",
    "df.feature.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bc36f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(11,4))\n",
    "plt.bar(df[df.importance > 0.5e-2].feature, df[df.importance > 0.5e-2].importance, color=\"gray\")\n",
    "plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59710410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quite Important\n",
    "df[df.importance > 1e-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b46ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not so important\n",
    "df[df.importance < 1e-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f69e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"CONFIG\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc7633d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
