{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63225f7b",
   "metadata": {},
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "coeffs = ['IP', 'BT', 'NEL', 'PLTH', 'RGEO', 'KAREA', 'EPS', 'MEFF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37eba013",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB2P8 = pd.read_csv(\"data/DB2P8.csv\")\n",
    "DB5 = pd.read_csv(\"data/DB5.csv\")\n",
    "\n",
    "DB2P8 = DB2P8[DB5.columns]\n",
    "\n",
    "# How was this chosen? Is this a form of removing outliers or noise to the new regression?\n",
    "# Why not simply use the whole DB5?\n",
    "new_ids = pd.read_csv(\"data/new_point_ids.csv\")\n",
    "\n",
    "data = pd.read_csv(\"data/data.csv\")\n",
    "                  \n",
    "r = pd.read_csv(\"data/R.csv\")#DB5[DB5.id.isin(new_ids.id.values)] #reintroduce dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f12f2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = DB2P8[[\"TAUTH\"]].apply(np.log).to_numpy()\n",
    "X = DB2P8[coeffs].apply(np.abs).apply(np.log).to_numpy()\n",
    "\n",
    "n, p = X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca8dbdc",
   "metadata": {},
   "source": [
    "$\\hat{\\beta} = (X^TX)^{-1}X^TY$;  $\\qquad H = X(X^TX)^{-1}X^T $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "266f782e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1310, 1310)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = np.matmul( np.linalg.inv( np.matmul(X.T,X) ) ,  np.matmul(X.T,Y))\n",
    "H = np.matmul(np.matmul( X,  np.linalg.inv( np.matmul(X.T, X) )),  X.T)\n",
    "\n",
    "H.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e49b37a",
   "metadata": {},
   "source": [
    "Leverage of the $i-th$ case: the diagonal element of the hat matrix\n",
    "\n",
    "$h_{ii} = x^T_i(X^TX)^{-1}x_i$ \n",
    "\n",
    "The residuals: $E = Y- \\hat{\\beta}X$\n",
    "\n",
    "MSE: $s^2 = \\sum^n_{i=1}\\frac{E^2_i}{n-p}$\n",
    "\n",
    "Studentized residual $r_i = E_i/s_{e_i}$\n",
    "\n",
    "$$\n",
    "    s_{e_i} = \\sqrt{s^2(1-h_{ii})} \\:\\: \\rightarrow \\:\\: r^*_i = \\frac{e_i}{s(i)\\sqrt{1-h_{ii}}}\n",
    "$$\n",
    "\n",
    "With $s^2(i)$ is the mean squared error when the $i-th$ case is omitted in fitting the regressio function. This follows the t-distribution with $n-p-1$ degrees of freedom; with assumptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "60407cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "E = Y - np.matmul(X,B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e596f4d",
   "metadata": {},
   "source": [
    "## DFBETA\n",
    "\n",
    "This is the parameter estimate after deleting the $i$-th observation; namely\n",
    "\n",
    "$$\n",
    "    \\text{DFBETA} = \\hat{\\beta} - \\hat{\\beta}_i = \\frac{X^TXx_iE_i}{1 - h_{ii}}\n",
    "$$\n",
    "\n",
    "with $C = (X^TX)^{-1}X^T$. If the x's are uniformly distributed then $c_{ij} = \\mathcal{O}(n^{-1})$. The DFBETA$_j$ vector is \n",
    "\n",
    "$$\n",
    "    \\text{DFBETA}_j = b_j - b_{ji} = \\frac{c_{ji}E_i}{1 - h_{ii}}\n",
    "$$\n",
    "\n",
    "\n",
    "When studying relative to the parameters, a scaled measure of the change can be done by \n",
    "\n",
    "$$\n",
    "    \\text{DFBETAS}_{ij} = \\frac{b_j - b_{ji}}{s(i)\\sqrt{(X^TX)^{-1}_{jj}}} = \\frac{c_{ij}}{\\sqrt{\\sum_{k=1}^n c^2_{ij}}}\\cdot\\frac{r^*_i}{\\sqrt{1-h_{ii}}}\n",
    "$$\n",
    "\n",
    "With $j=1,\\ldots,p$ and $b_j$ being the $j$-th element of the $\\hat{\\beta}$ parameter. The denominator of DFBETAS$_{ij}$ is similar to the estimated standard deviation of $\\hat{\\beta}$ with the sample standard error $s$ replaced by the deleted-one version $s(i)$. BKW proposed a cutoff: $2\\cdot n ^{-1/2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8b4a510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10480"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e1e133",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
